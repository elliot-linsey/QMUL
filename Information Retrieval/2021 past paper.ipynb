{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0fa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1251f0",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "i) False, the boolean model has queries specified as boolean expressions\n",
    "\n",
    "ii) False, Frequent words have less discriminatory power, if it appears in every document then it probably isn't very important\n",
    "\n",
    "iii) True, a term that is rare is more informative. For a very specific subject the word should be weighted highly. \n",
    "\n",
    "iv) True, the bag of words model takes counts of each word per document and removes sentence structure\n",
    "\n",
    "v) False, it treats all words the same so the higher the word frequency, the higher the score which is the opposite of what is wanted\n",
    "\n",
    "vi) False, high dot products means documents are similar\n",
    "\n",
    "vii) True, base of log doesn't affect\n",
    "\n",
    "viii) False, stemming usually increases recall but decreases precision. \n",
    "\n",
    "ix) False, stemming usually increases recall\n",
    "\n",
    "x) False, The most frequent word occurs approximately twice as often as the second most frequent word. The frequency is inversely proportional to its rank in the frequency table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42e209",
   "metadata": {},
   "source": [
    "b) done in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064065f7",
   "metadata": {},
   "source": [
    "c) Force Jedi is the best\n",
    "\n",
    "Force Jedi has Dark Hope\n",
    "\n",
    "Force Jedi has Hope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78ad5f",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "TF = term frequency of term t in collection\n",
    "\n",
    "tf = term frequency of term t in document\n",
    "\n",
    "p = probability to draw a document, = 1/N where N is number of documents\n",
    "\n",
    "w(t|d) is the weight of the term given the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede2978",
   "metadata": {},
   "source": [
    "-np.log10("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b77a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = (4/20 * 13/24)/(11/24 * 16/20)\n",
    "c2 = (8/20 * 16/24)/(8/24 * 12/20)\n",
    "c3 = (4/20 * 14/24)/(10/24 * 16/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81e6215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6287878787878787\n",
      "1.9787878787878788\n",
      "0.29545454545454547\n",
      "ranking = d2,d1,d3\n"
     ]
    }
   ],
   "source": [
    "print(c1 + c2)\n",
    "print(c1 + c2 + c3)\n",
    "print(c1)\n",
    "print('ranking = d2,d1,d3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab31249",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "a) both u and v are webpages. U is the set of pages. PR is the pagerank of the specific webpage u or v. N is the number of outgoing links of page v. d is the damping factor.\n",
    "\n",
    "For the iteration, Qianni first works out the PR for A, then uses the updated PR value for calculating the rest. I'm not 100% if that's actually correct but it is how she does it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850448c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4 + 0.6*1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75fddb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4 + 0.6*(1/2 + 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0b4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999999999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4 + 0.6*(1/2 + 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd42e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4 + 0.6*1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba62472",
   "metadata": {},
   "source": [
    "ci) it assumes that the index terms are linearly independent but no longer pairwise orthogonal\n",
    "\n",
    "cii) minterm vectors\n",
    "\n",
    "ciii) (1,0,...0), (0,1...,0), (0,0...1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7aad5",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "ai) Recall is usually impossible as we may not know all relevant documents\n",
    "\n",
    "As one increases the other usually decreases \n",
    "\n",
    "precision and recall don't take into account ranking\n",
    "\n",
    "ii) precision favours web search where we want relevant documents ranked highly. recall favours medicine or law where we want an exhaustive list of all relevant documents \n",
    "\n",
    "iii) E-measure allows the user to specify whether they are more interested in precision or recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56a96b",
   "metadata": {},
   "source": [
    "ci) cluster hypothesis is Documents in the same\n",
    "cluster behave similarly with respect to relevance to\n",
    "information needs\n",
    "\n",
    "cii) whole corpus analysis/navigation, for improving recall in search applications, for better navigation of search results\n",
    "\n",
    "ciii) newspaper wants to put news stories into categories, spam filter for relevant or not relevant, find the category of a given web page\n",
    "\n",
    "d) the semantic gap is the difference between two or more descriptions of an object in different representations. For example, both words 'movie' and 'film' may be relating to the same subject but due to the semantic gap between them they may not appear similar in an information retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e42f459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2236930455635492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2*(1-0.417)/0.417*(1-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1262289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8939999999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.189 + 0.481 + 0.224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f17396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7928932188134525"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topleft = (1-(0.5)**0.5)**2\n",
    "topright = (1-1)**2\n",
    "combinedtop = (topleft+topright)/2\n",
    "full = 1-combinedtop**0.5\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b72abb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.246950765959598"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8**2 + 4**2 + 5**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2152dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15e51ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78071631, 0.39035815, 0.        , 0.48794769])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([8,4,0,5])/10.247"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
