{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "In this lab, you will complete the full process of describing and then implementing an algorithm. You will do so on a topic relevant to data science: _(simple) linear regression_. Please note that this lab is assessed, i.e., you will need to submit the results of your work on QM+. To submit your work, first download/export your Jupyter notebook as PDF. Then upload the PDF file in the submission area on QM+."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Simple Linear Regression\n",
    "If necessary (depending on your background), read up on (simple) linear regression. Wikipedia (https://en.wikipedia.org/wiki/Simple_linear_regression) provides a good starting point, but you might as well choose other sources. (You do not need to include any information about this in your submission.)\n",
    "\n",
    "## Task 1: Describe Linear Regression in English\n",
    "Given a dataset of $n$ values $(x_i, y_i)$ for $1 \\leq i \\leq n$, describe the process to compute values $\\alpha$ and $\\beta$ such that $$\\sum_{i = 1}^n (y_i - \\alpha x_i - \\beta)^2$$ is minimal. This will yield a (linear) model $y = \\alpha x + \\beta$ adhering to the least-squares condition.\n",
    "> Marking information: Up to 30 points: 15 points for an algorithm that can be followed, and 15 points for the correctness of this algorithm against the specification \"linear regression.\"\n",
    "\n",
    "### Solution:\n",
    "> Linear regression is a method to gauge the statistical relationship between a dependent variable (response), and an independent variable (predictor). Linear regression assumes that the relationship between these two variables is linear, i.e., the line of best fit through the data points is a straight line. There can be an infinite number of lines that are fitted through a data set but the line of best fit is defined as one where the sum of the squares of the difference between the predicted value and the actual value (i.e., the sum of the squares of the errors) is minimum. This is also known as the least squares estimate.\n",
    "<br><br>\n",
    "Let's consider a model function $y = \\alpha x + \\beta$.\n",
    "<br><br>\n",
    "> Given a dataset of $n$ values $(x_i, y_i)$ for $1 \\leq i \\leq n$, for every element, the relationship between $y_i$ and $x_i$ can be defined as: $$y_i = \\alpha x_i + \\beta + \\epsilon_i $$ <br> where $\\epsilon_i$ is the error between the predicted value and the actual value. <br><br>\n",
    "> This can be written as: $$\\epsilon_i = y_i - \\alpha x_i - \\beta$$ <br>\n",
    "As mentioned previously, the line of best fit (a linear regression line) is defined as one where the sum of the square of the errors is minimum, i.e., $$\\sum_{i = 1}^n\\epsilon_i^2$$ is minimum OR $$\\sum_{i = 1}^n (y_i - \\alpha x_i - \\beta)^2$$ is minimum.<br><br>\n",
    "This implies that $\\alpha$ and $\\beta$ need to be found where:\n",
    "$$\\begin{equation*}\n",
    "\\frac{\\partial \\sum_{i = 1}^n (y_i - \\alpha x_i - \\beta)^2}{\\partial \\alpha} = 0\n",
    "\\label{eq:alpha_init} \\tag{1}\n",
    "\\end{equation*}\n",
    "$$\n",
    "<br>\n",
    "$$\\begin{equation*}\n",
    "\\frac{\\partial \\sum_{i = 1}^n (y_i - \\alpha x_i - \\beta)^2}{\\partial \\beta} = 0\n",
    "\\label{eq:beta_init} \\tag{2}\n",
    "\\end{equation*}\n",
    "$$\n",
    "Solving $\\eqref{eq:alpha_init}$ and $\\eqref{eq:beta_init}$, $\\alpha$ and $\\beta$ can be reduced to:\n",
    "$$\\begin{equation*}\n",
    "\\alpha = \\frac{\\sum_{i = 1}^n (x_i - \\bar x)(y_i - \\bar y)}{\\sum_{i = 1}^n (x_i - \\bar x)^2}\n",
    "\\label{eq:alpha} \\tag{3}\n",
    "\\end{equation*}\n",
    "$$\n",
    "<br>\n",
    "$$\\begin{equation*}\n",
    "\\beta = \\bar y - \\alpha \\bar x\n",
    "\\label{eq:beta} \\tag{4}\n",
    "\\end{equation*}\n",
    "$$ where $\\bar x$ and $\\bar y$ are $\\sum_{i=1}^n \\frac{x_i}{n}$ and $\\sum_{i=1}^n \\frac{y_i}{n}$ respectively.\n",
    "<br><br>\n",
    "Please note that the derivation was carried out by hand but not included here. The result however matches the generally accepted equations for $\\alpha$ and $\\beta$ found on multiple sources including https://online.stat.psu.edu/stat462/node/92/.\n",
    "<br><br>\n",
    "To solve for $\\alpha$ and $\\beta$ for a given data set as defined above, <b> the algorithm can be defined as follows: </b>\n",
    ">1. Get the x and y values, and the number ($n$) of x or y values (assume that a dataset is clean and number of x values and y values are equal)\n",
    ">2. Add all x values to get sum of $x_i$\n",
    ">3. Add all y values to get sum of $y_i$\n",
    ">4. Divide sum of x values and sum of values by $n$ to get $\\bar x$ and $\\bar y$ respectively\n",
    "<br>Solve for $\\alpha$ first:\n",
    ">5. Subtract each x value by $\\bar x$\n",
    ">6. Subtract each y value by $\\bar y$\n",
    ">7. Multiply each element of 5, with each element of 6\n",
    ">8. Add all the elements in 7 to get the value of the numerator in $\\eqref{eq:alpha}$\n",
    ">9. Square the elements in 5, and add them to get the denominator in $\\eqref{eq:alpha}$\n",
    ">10. Divide 9 by 10 to get the value of $\\alpha$ \n",
    "<br>Solve for $\\beta$:\n",
    ">11. Multiply $\\alpha$ by $\\bar x$ (found in 4)\n",
    ">12. Subtract $\\bar y$ by the value found in 11\n",
    ">13. Outputs: $\\alpha$ and $\\beta$\n",
    "\n",
    "## Task 2: Create and Complete a Simple Example\n",
    "Come up with a dataset of just 3 values ($\\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}$). Then exercise the algorithm of Task 1 on this small dataset. You might prefer to do this using pen and paper. For your submission, provide at least the dataset that you have chosen and the resulting values of $\\alpha$ and $\\beta$.\n",
    "> Marking information: Up to 20 points: 5 points for sample values, and up to 15 points for suitable values of $\\alpha$ and $\\beta$.\n",
    "\n",
    "### Solution:\n",
    ">Let the dataset of 3 values be:\n",
    ">$$ Data =  \\{(1, 10), (2, 18), (3, 35)\\}$$\n",
    "<br>\n",
    "Therefore, $$\\bar x = (1 + 2 + 3)/3 = 2$$ and <br> $$ \\bar y = (10 + 18 + 35)/3 = 21$$\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th></th>\n",
    "    <th>x_i</th>\n",
    "    <th>y_i</th>\n",
    "    <th>x_i - xbar</th>\n",
    "    <th>y_i - ybar</th>\n",
    "    <th>(x_i - xbar)*(y_i - ybar)</th>\n",
    "    <th>(x_i - xbar)^2</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td></td> \n",
    "    <td>1</td> \n",
    "    <td>10</td>\n",
    "    <td>-1</td> \n",
    "    <td>-11</td>\n",
    "    <td>11</td> \n",
    "    <td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td></td> \n",
    "    <td>2</td> \n",
    "    <td>18</td>\n",
    "    <td>0</td> \n",
    "    <td>-3</td>\n",
    "    <td>0</td> \n",
    "    <td>0</td>   \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td></td> \n",
    "    <td>3</td> \n",
    "    <td>35</td>\n",
    "    <td>1</td> \n",
    "    <td>14</td>\n",
    "    <td>14</td> \n",
    "    <td>1</td>   \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td><b>Sums</b></td> \n",
    "    <td>6</td> \n",
    "    <td>63</td>\n",
    "    <td>0</td> \n",
    "    <td>0</td>\n",
    "    <td>25</td> \n",
    "    <td>2</td>   \n",
    "</tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    ">Therefore, $$\\alpha = 25/2$$ and $$\\beta = \\bar y - \\frac{25}{2}(\\bar x) = -4$$\n",
    "\n",
    "\n",
    "## Task 3: Implement the Algorithm of Task 1 in Python\n",
    "Starting from your description of the steps to undertake, transfer English and Maths to Python. Note that you are expected to fully implement the mathematical operations instead of using a library function such as `scikit` or `statsmodels`.\n",
    "> Marking information: Up to 40 points: 30 points for a correctly working Python implementation, and 10 points for comments and overall readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(list_xy):\n",
    "    #Get the x and y values, and the number (n) of x or y values (assume that a dataset is clean and number of x values and y values are equal)\n",
    "    list_x = [list_xy[i][0] for i in range(len(list_xy))]\n",
    "    list_y = [list_xy[i][1] for i in range(len(list_xy))]\n",
    "    \n",
    "    num_items = len(list_x)\n",
    "    \n",
    "    #Add all x values to get sum of $x_i$\n",
    "    x_sum = sum(list_x)\n",
    "    \n",
    "    #Add all y values to get sum of $y_i$\n",
    "    y_sum = sum(list_y)\n",
    "    \n",
    "    #Divide sum of x values and sum of values by $n$ to get $\\bar x$ and $\\bar y$ respectively\n",
    "    x_mean = x_sum/num_items\n",
    "    y_mean = y_sum/num_items\n",
    "    \n",
    "    #Solve for $\\alpha$ first:\n",
    "    #Subtract each x value by $\\bar x$\n",
    "    x_subtracted = [val-x_mean for val in list_x]\n",
    "    \n",
    "    #Subtract each y value by $\\bar y$\n",
    "    y_subtracted = [val-y_mean for val in list_y]\n",
    "    \n",
    "    #Multiply each element of x_subtracted by each element of y_subtracted\n",
    "    x_sub_mult_y_sub = [x_subtracted[i] * y_subtracted [i] for i in range(len(x_subtracted))]\n",
    "    \n",
    "    #Add all the elements in x_sub_mult_y_sub to get the value of the numerator in the equation for alpha\n",
    "    alpha_numerator = sum(x_sub_mult_y_sub)\n",
    "    \n",
    "    #Square the elements in x_subtracted, and add them to get the denominator in tthe equation for alpha\n",
    "    alpha_denominator = sum([i**2 for i in x_subtracted])\n",
    "    \n",
    "    #Divide alpha_numerator by alpha_denominator to get the value of alpha \n",
    "    alpha = alpha_numerator/ alpha_denominator\n",
    "    \n",
    "    #Solve for $\\beta$\n",
    "    #Multiply $\\alpha$ by x_mean\n",
    "    #Subtract $\\bar y$ by alpha * x_mean\n",
    "    \n",
    "    beta = y_mean - (alpha * x_mean)\n",
    "    \n",
    "    #Outputs: $\\alpha$ and $\\beta$    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Test the Implementation of Task 3\n",
    "Use at least the dataset of Task 2, or possibly also other datasets, to exercise your implementation of Task 3.\n",
    "> Marking information: Up to 10 points for Python instructions to run the test and the comparison to expected values previously found using pen and paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12.5, -4.0)\n",
      "(5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "list_xy = [[1,10],[2,18],[3,35]]\n",
    "test_xy = [[1,5],[2,10]]\n",
    "empty_xy = [[]]\n",
    "print(linear_regression(list_xy))\n",
    "print(linear_regression(test_xy))\n",
    "#print(linear_regression(empty_xy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above tests that:\n",
    ">a. the code returns the same values as what was found by hand in Task 3 for the same dataset<br>\n",
    "b. for a perfect data set, the code returns the expected alpha and beta values, thus instilling confidence in the code<br>\n",
    "c. for a test dataset of less than two elements, the code returns an error as expected<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Additional work\n",
    "\n",
    "Using sample data set from https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/data/poverty/index.txt,\n",
    "we are going to look at the relationship between poverty percentage and teen birth rate in 50 states in the US and District of Columbia (n = 51). The y values are the birth rates for 15-17 year olds in the year 2002, and the x values are the poverty rate, which is the percent of the state’s population living in households with incomes below the federally defined poverty level.\n",
    "\n",
    "We will extract the relevant data from the file, and test our code (written in task 3) to test whether the alpha and beta values match those given in https://online.stat.psu.edu/stat462/node/101/, and those outputed by using standard python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'%'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8d9612199ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Alpha = {%.3f} and beta = {%.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '%'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/data/poverty/index.txt', sep = \"\\t\")\n",
    "\n",
    "#print(data)\n",
    "\n",
    "#Copy the relevant columns to lists so that we can use them in our linear_regression code (task 3)\n",
    "pov_pct = data['PovPct'].tolist()\n",
    "\n",
    "birth_rate = data['Brth15to17'].tolist()\n",
    "\n",
    "x=np.array(pov_pct)\n",
    "y=np.array(birth_rate)\n",
    "\n",
    "alpha, beta = np.polyfit(x,y,1)\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x, alpha*x + beta )\n",
    "\n",
    "print(\"Alpha = {%.3f} and beta = {%.3f}\".format(alpha, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the alpha and beta values are the same as the ones in the original source (https://online.stat.psu.edu/stat462/node/101/)\n",
    "\n",
    "Next, we will compare the alpha and beta values to our code in task 3 to see if our code is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3733453886953968, 4.267292842407446)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since our function only accepts a list of lists ([[x1,y1],[x2,y2],..]), we need to combine pov_pct and \n",
    "#birth_rate above into one list\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(pov_pct)):\n",
    "    data_list.append([pov_pct[i],birth_rate[i]])\n",
    "\n",
    "linear_regression(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
