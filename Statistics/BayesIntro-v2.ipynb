{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "international-resolution",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ECS7024: Introduction to Bayesian Statistics\n",
    "\n",
    "*Version 2.0*\n",
    "\n",
    "This notebook accompanies the introduction to Bayesian Statistics (topic 18). The aim of this topic is to gain awareness of Bayesian statistics. It is not expected that students are able to run these analyses; you will not be asked to do this for a coursework. Except for Section 3, the notebook will not run on jhub.\n",
    "\n",
    "If you do wish to run this notebook you need to install the following libraries:\n",
    "\n",
    "  * [Pymc3: Probabilistic Programming in Python](https://docs.pymc.io/)\n",
    "  * [ArviZ: Exploratory analysis of Bayesian models](https://arviz-devs.github.io/arviz/)\n",
    "\n",
    "\n",
    "**Contents**\n",
    "  1. Section 1: Binomial Distribution\n",
    "     1.  Section 1.1: Likelihood\n",
    "     2.  Section 1.2: Prior\n",
    "     3.  Section 1.3: Calculating the Posterior\n",
    "  2. Section 2: Regression Model\n",
    "     1.  Section 2.1: Simulating Data\n",
    "     2.  Section 2.2: Specifying the Model\n",
    "     3.  Section 2.3: Displaying the Posteriors\n",
    "  3. Section 3: Binomial Again: Direct Implementation\n",
    "     1.  Section 3.1: The Algorithm\n",
    "     2.  Section 3.2: Examples: Varying the Prior\n",
    "     3.  Section 3.2: Examples: Zero Successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2484f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymc3\n",
    "# !pip install arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "funny-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "The installed Theano(-PyMC) version (1.0.4) does not match the PyMC3 requirements.\n",
      "It was imported from ['C:\\\\Users\\\\ellio\\\\anaconda3\\\\lib\\\\site-packages\\\\theano']\n",
      "For PyMC3 to work, a compatible Theano-PyMC backend version must be installed.\n",
      "See https://github.com/pymc-devs/pymc3/wiki for installation instructions.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TheanoConfigParser' object has no attribute 'gcc__cxxflags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ff70eb3b71cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpymc3\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0m_check_backend_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0m__set_compiler_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0m_hotfix_theano_printing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\__init__.py\u001b[0m in \u001b[0;36m__set_compiler_flags\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m__set_compiler_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# Workarounds for Theano compiler problems on various platforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mcurrent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcc__cxxflags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcc__cxxflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{current} -Wno-c++11-narrowing\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TheanoConfigParser' object has no attribute 'gcc__cxxflags'"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-triple",
   "metadata": {},
   "source": [
    "## Section 1: Binomial Distribution \n",
    "In this section we look at a binomial distribution. Recall that the parameters of a binomial distribution are:\n",
    "  1. The number of trials (n)\n",
    "  2. The probability of success (p)\n",
    "\n",
    "and that the distribution gives the probability of the number of successes, in the range 0 to n. Imagine that we have gathered data and know both n (the number of trials) and the number of successes. What is p (the probability of success)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-leeds",
   "metadata": {},
   "source": [
    "### Section 1.1 Likelihood\n",
    "\n",
    "In this simple case we can evaluate the probability of the evidence directly. Suppose that the number of trails (n) is 100 and the number of successes (x) is 25. So the usual estimate is 25/100.\n",
    "\n",
    "We see that the probabilities are quite small. Seeing numbers of successes that are close (such as 23, 24, 2,6, 27) is just as likely, even if the true probability of success is 25%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 25 # successes\n",
    "n = 100 # trials\n",
    "evidence_prob = pd.DataFrame(data = {'Param': np.arange(0.1,0.5,0.01)})\n",
    "evidence_prob = evidence_prob.assign(Prob = evidence_prob.apply(lambda row: stats.binom.pmf(x, n, row.Param), axis=1))\n",
    "evidence_prob = evidence_prob.assign(Log = evidence_prob.apply(lambda row: np.log(row.Prob), axis=1))\n",
    "evidence_prob[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-chess",
   "metadata": {},
   "source": [
    "**Likelihood Function** This shows the probability of getting the data that we observed varies with the *success probabiliy* which is the parameter of the binomial distribution. We plot this with and without logs.\n",
    "\n",
    "Note that **neither** plot is a probability distribution. In $p(\\mbox{data} ~|~ \\theta)$ we have a probability distribution over the different possible data values for a given $\\theta$. However, in these plots, it is $\\theta$ that varies which the data observed stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (a1, a2) = plt.subplots(1,2,figsize=(12, 6))\n",
    "evidence_prob.plot(kind = \"line\", y=\"Prob\", x = \"Param\", ax=a1)\n",
    "evidence_prob.plot(kind = \"line\", y=\"Log\", x = \"Param\", ax=a2)\n",
    "a1.set_xlabel(\"Probability of Success\")\n",
    "a2.set_xlabel(\"Probability of Success\")\n",
    "a1.set_ylabel(\"Probability of observing 25 successes in 100 trials\")\n",
    "_ = a2.set_ylabel(\"Log of Prob of observing 25 successes in 100 trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-constant",
   "metadata": {},
   "source": [
    "### Section 1.2: Prior Probability\n",
    "\n",
    "We need to specify a prior distribution for the unknown parameter, the probability of success. The beta distribution is often used for this, because the Bayesian formula has an analytic solution in this case. Although this is not relevant to use, we can still use the beta distribution: as it ranges the interval 0 to 1, it is a suitable way to specify a prior for a probability.\n",
    "\n",
    "The following disagram shows some beta distributions for different parameters. We see that Beta(1, 1) is a uniform distribution on the interval 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "def meanBeta(a, b): return a / (a + b)\n",
    "def modeBeta(a, b): return (a - 1) / (a + b - 2)\n",
    "\n",
    "x = np.linspace(stats.beta.ppf(0.01, 1, 1), stats.beta.ppf(0.99, 1, 1), 100)\n",
    "ax.plot(x, stats.beta.pdf(x, 1, 1), 'r-', label=('beta(1, 1), mean = %3.2f' % meanBeta(1, 1)))\n",
    "ax.plot(x, stats.beta.pdf(x, 1.5, 1.5), 'k-', label=('beta(1.5, 1.5), mean = %3.2f, mode = %3.2f' % (meanBeta(1.5, 1.5), modeBeta(1.5, 1.5))))\n",
    "ax.plot(x, stats.beta.pdf(x, 3, 7), 'b-', label=('beta(3, 7), mean = %3.2f, mode = %3.2f' % (meanBeta(3, 7), modeBeta(3, 7))))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-presentation",
   "metadata": {},
   "source": [
    "### Section 1.3: Calculating the Posterior\n",
    "Recall the Bayesian formula:\n",
    "$$\n",
    "p(\\theta \\mid \\mbox{data}) = \\frac{p(\\mbox{data} \\mid \\theta) . p(\\theta)}{p(\\mbox{data})}\n",
    "$$\n",
    "where $\\theta$ stands for all the uncertian parameters of the model. In this example, there is only one such parameter but often (as in the second example below) there are many parameters. So we are, in general, seeking to represent a multivariate probability distribution.\n",
    "\n",
    "The representation that is used is a list of samples. Random (so called 'Monte Carlo') methods are used to create the samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running on PyMC3 v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-alabama",
   "metadata": {},
   "source": [
    "**Model Specification in PyMC3**\n",
    "\n",
    "The first step is to specify the model. First the model is introduced and then the variables are added. We have added two variables using different priors. It takes several seconds to generate the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom_model = pm.Model()\n",
    "\n",
    "with binom_model:\n",
    "\n",
    "    # Priors for unknown model parameters\n",
    "    p1 = pm.Beta(\"p1\", alpha=1.0, beta=1.0)\n",
    "    p2 = pm.Beta(\"p2\", alpha=3.0, beta=7.0)\n",
    "    \n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    NSucc1 = pm.Binomial(\"NSucc1\", p=p1, n=100, observed=25)\n",
    "    NSucc2 = pm.Binomial(\"NSucc2\", p=p2, n=100, observed=25)\n",
    "    \n",
    "    # draw posterior samples\n",
    "    trace = pm.sample(2000, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-wallace",
   "metadata": {},
   "source": [
    "The distribution can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "with binom_model:\n",
    "    az.plot_dist(trace[\"p1\"], color=\"r\", label=\"Uniform prior\")\n",
    "    ax = az.plot_dist(trace[\"p2\"], color=\"b\", label=\"Prior beta(3, 7)\")\n",
    "    ax.set_xlabel(\"Success Probability\", fontsize=14)\n",
    "    ax.set_ylabel(\"Density\", fontsize=14)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-protection",
   "metadata": {},
   "source": [
    "Another form of plot shows the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with binom_model:\n",
    "    az.plot_forest(trace, var_names=['p1', 'p2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-unemployment",
   "metadata": {},
   "source": [
    "## Section 2: Linear Regression\n",
    "\n",
    "This section demonstrates Bayesian inference for a regression model. \n",
    "\n",
    "### Section 2.1 Simulating Data\n",
    "Data for the regression is simulated by setting some regression coefficient and an intercept and then simulating data from the regression equation plus a normally-distributed random offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "# True parameter values\n",
    "alpha, sigma = 1, 1\n",
    "beta = [1, 2.5]\n",
    "\n",
    "# Size of dataset\n",
    "size = 100\n",
    "\n",
    "# Predictor variable\n",
    "X1 = np.random.randn(size)\n",
    "X2 = np.random.randn(size) * 0.2\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(size)*sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-pierre",
   "metadata": {},
   "source": [
    "**Residuals**\n",
    "We can plot the residuals in the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = alpha + beta[0]*X1 + beta[1]*X2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Y, Y_hat, lw=0.0, ms=2.0, marker='x')\n",
    "ax.set_xlabel(\"True Value\")\n",
    "_ = ax.set_ylabel(\"Predicted Value\")\n",
    "\n",
    "ys = np.arange(-2.0, 5.0, 0.1)\n",
    "ax.plot(ys, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-scientist",
   "metadata": {},
   "source": [
    "### Section 2.2 Specifying the Model\n",
    "\n",
    "The model is specified using 4 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = pm.Model()\n",
    "\n",
    "with regression:\n",
    "\n",
    "    # Priors for unknown model parameters\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=10)\n",
    "    beta = pm.Normal('beta', mu=0, sd=10, shape=2)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta[0]*X1 + beta[1]*X2\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = pm.Normal('Y_obs', mu=mu, sd=sigma, observed=Y)\n",
    "    \n",
    "    trace = pm.sample(2000, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-cinema",
   "metadata": {},
   "source": [
    "### Section 2.3 Displaying the Posterior\n",
    "\n",
    "The following plot shows the full trace, with the density plots of the intercept (alpha), the two coeffecients (beta) and the variance of the error (sigma). This is followed by a forest plot. \n",
    "\n",
    "All the values are close to the true parameter values used in the model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "with regression:\n",
    "    az.plot_trace(trace, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "with regression:\n",
    "    az.plot_forest(trace, var_names=['alpha', 'beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-request",
   "metadata": {},
   "source": [
    "## Section 3: Binomial Again: Direct Implementation\n",
    "In this section we look again at a binomial distribution, but now do the calculations directly, without using pyMC. \n",
    "\n",
    "We want to estimate the probability $p$ of a binomial after a given number of trials $n$ with $x$ successes. In the following equation:\n",
    "$\n",
    "   p(\\theta \\mid D) \\propto  p(D \\mid \\theta) . p(\\theta)\n",
    "$\n",
    " *  $\\theta$ is the unknown parameter of a probability distribution, to be estimated from data\n",
    " *  $D$ is the data, i.e. the results of observation or experiment\n",
    "\n",
    "\n",
    "The steps to sample from the posterior distribution are:\n",
    " 1. Sample $\\theta$ from prior distribution (e.g uniform)\n",
    " 2. Calculate the likelihood of the data using the sampled $\\theta$\n",
    " 3. Normalize the weights\n",
    " 4. Plot a histogram of weighted samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-tribe",
   "metadata": {},
   "source": [
    "### Section 3.1: The Algorithm\n",
    "\n",
    "We create a data frame with the following variables:\n",
    "  1. theta: the unknown parameter(s) to be inferred\n",
    "  2. weight: the likelihood weightings\n",
    "\n",
    "The theta values are sampled from the prior distribution. The likelihood is calculated using the PMF of the binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binomial proportion posterior distribution\n",
    "def binPropDist(trials, success, prior, samples=50000):\n",
    "    df = pd.DataFrame()\n",
    "    df = df.assign(theta = prior.rvs(samples))\n",
    "    df = df.assign(weight = \n",
    "                   df.apply(lambda r: stats.binom.pmf(success, trials, r.theta), \n",
    "                            axis=1))\n",
    "    df.weight = df.weight / np.sum(df.weight)\n",
    "    return df\n",
    "\n",
    "def plotBinPropDist(df, text, lower=0, upper=1):\n",
    "    fg, a1 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    df1 = df.loc[(df.theta >= lower) & (df.theta <= upper)]\n",
    "    bins=int(np.ceil(2*np.power(len(df1), 1/3)))\n",
    "    df1.hist(column='theta', weights=df1.weight, bins=bins, density=True, ax=a1)\n",
    "    a1.set_title('Posterior Distribution of p, for %s' % text)\n",
    "    a1.set_xlabel('Unknown Parameter Binomial Proportion p')\n",
    "    a1.set_ylabel('Density')\n",
    "    return a1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-metro",
   "metadata": {},
   "source": [
    "### Section 3.2: Examples: Varying the Prior\n",
    "These examples use $n=10$ and $x=2$ with different prior distributions:\n",
    "\n",
    "  * Uniform\n",
    "  * Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binPropDist(10, 2, stats.uniform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plotBinPropDist(df, \"2 Successes in 10 Trials, Uniform Prior\")\n",
    "x = np.linspace(0, 1, 100)\n",
    "ax.plot(x, stats.uniform.pdf(x), 'r-', lw=3, alpha=0.6, label='beta pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta = binPropDist(10, 2, stats.beta(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = plotBinPropDist(df_beta, \"2 Successes in 10 Trial, prior Beta(2,5)\")\n",
    "x = np.linspace(0, 1, 100)\n",
    "a1.plot(x, stats.beta.pdf(x, 2, 5), 'r-', lw=3, alpha=0.6, label='beta pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta2 = binPropDist(10, 2, stats.beta(2, 2))\n",
    "a1 = plotBinPropDist(df_beta2, \"2 Successes in 10 Trial, prior Beta(2,2)\")\n",
    "x = np.linspace(0, 1, 100)\n",
    "a1.plot(x, stats.beta.pdf(x, 2, 2), 'r-', lw=3, alpha=0.6, label='beta pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-january",
   "metadata": {},
   "source": [
    "### Section 3.3: Examples: Zero Successes\n",
    "We explore this for different numbers of trials:\n",
    "\n",
    " 1. 10 trials\n",
    " 2. 100 trials\n",
    " 3. 500 trials\n",
    "\n",
    "\n",
    "All cases use a uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni1 = binPropDist(10, 0, stats.uniform())\n",
    "_ = plotBinPropDist(df_uni1, \"0 Success in 10 Trials, Uniform Prior\", \n",
    "                    lower=0, upper=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni2 = binPropDist(100, 0, stats.uniform())\n",
    "_ = plotBinPropDist(df_uni2, \"0 Success in 100 Trials, Uniform Prior\", \n",
    "                    lower=0, upper=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni2 = binPropDist(500, 0, stats.uniform(), samples=100000)\n",
    "_ = plotBinPropDist(df_uni2, \"0 Success in 500 Trials, Uniform Prior\", \n",
    "                    lower=0, upper=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-thesis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
