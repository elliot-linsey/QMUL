{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECS7024 Statistics for Artificial Intelligence and Data Science\n",
    "\n",
    "\n",
    "## Notebook 3: Aims and Outline\n",
    "\n",
    "The overall aim of this notebook is to gain familiarity with correlations (in the broad sense of the influence of one variable on another) for both continuous and categorical variables. We first explore correlation, then cross tabulation and finally the distribution of continuous variables conditioned by a categorical one. \n",
    "\n",
    "The first section gives some details of the data. No depth of understanding of bridges is expected! \n",
    "\n",
    " 1. Section 1: Introducing the Data Set\n",
    "     1. The Source of the Data and the Variables\n",
    "     1. Loading the Data\n",
    "     1. Initial Exploration\n",
    "     \n",
    " 1. Section 2: Correlation of Continuous Variables\n",
    "     1. Correlation Matrix\n",
    "     1. Scatter and other X-Y Plots\n",
    "     1. The Scatter Matrix\n",
    " \n",
    " 1. Section 3: Cross-tabulating Categorical Variables\n",
    "     1. Cross Tabulation and Normalisation\n",
    "     1. Plotting Conditional Probability Distributions\n",
    "     1. Heat map of (Conditional) Probabilities\n",
    "     \n",
    " 1. Section 4: Distributions of Continuous Variables, by Category\n",
    "     1. Using Box Plots to Compare the Distribution of one Variable by Another Variable\n",
    "     1. Using Group By to Partition a Data Frame\n",
    "     1. Reducing the Number of Categories\n",
    "     1. Comparing Groups using Histograms and Kernel Density\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   # this is an additional plotting library\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introducing the Data Set\n",
    "\n",
    "This notebook looks at some data from the US National Bridge Inspection maintained by the Federal Highways Agency (FHWA), part of the US Department of Transportation. The original data comes from the [National Bridge Inspection](https://www.fhwa.dot.gov/bridge/nbi/ascii.cfm) section of the FHWA's web site. However, it has been greatly simplified. If you are interested in a particular bridge, you can use the structure number to look it up (including on google maps, where the satellite imaging shows a picture) on the (Info Bridge System)[https://infobridge.fhwa.dot.gov/].\n",
    "\n",
    "**The aim of the Bridge Inspection programme is to check on the state of bridges so that necessary repairs can be carried out. If this is not done, a bridge can fail. The dataset has information about the bridges and the condition given in the most recent inspection.**\n",
    "\n",
    "* The FHWA's database covers the whole USA. Our data is only for the state of Texas. \n",
    "* As well as bridges, the FHWA's database covers tunnels (there seem to be no highway tunnels in Texas) and 'culverts'. A culvert is a form of drain, allowing water to pass under a highway. The culverts have been removed, leaving only the bridges.\n",
    "* All of the bridges carry a highway (that is, a road runs over the bridge). What is underneath varies: another road, a waterway or a railway are among the possibilities. \n",
    "\n",
    "### Section 1.1 The Variables\n",
    "The original FHWA dataset has over 100 variables (Texas collects even more); ours is simplified. Both continuous and categorical variables are included. \n",
    "\n",
    "\n",
    "| Variable      |      Description             | Type | \n",
    "|:--------------|:-----------------------------|:------:|\n",
    "|Structure_id   | Unique identifier of the bridge                  | String |\n",
    "|District       | Highway district in Texas responsible for bridge | category | \n",
    "|Detour_Km      | Length of detour if bridge closed                | continuous |\n",
    "|Toll           | Whether a toll is paid to use bridge             | category |\n",
    "|Maintainer     | The authority responsible for maintenance        | category |\n",
    "|Urban          | Whether the bridge is located in an urban or rural area   | category |\n",
    "|Status         | The road class: interstate to local                       | category | \n",
    "|Year           | The year the bridge was built                             | continuous | \n",
    "|Lanes_on       | The number of lanes that run over the bridge              | continuous (or discrete) |\n",
    "|Lanes_under    | The number of lanes that run under the bridge             | continuous (or discrete) |\n",
    "|AverageDaily   | The average daily traffic (number of vehicles)            | continuous |\n",
    "|Future_traffic | The estimated daily traffic in approx 20 years time       | continuous |\n",
    "|Trucks_percent | The percent of traffic made up of 'trucks' (i.e. lorries) | continuous |\n",
    "|Historic       | Whether the bridge is historic                            | category | \n",
    "|Service_under  | The (most important) service that runs under the bridge   | category |\n",
    "|Material       | The dominant material the bridge is made from             | category |\n",
    "|Design         | The design of the bridge                                  | category |\n",
    "|Spans          | The number of spans the bridge has                        | category (or discrete) |\n",
    "|Length         | The length of the bridge in metres                        | continuous |\n",
    "|Width          | The width of the bridge in metres                         | continuous |\n",
    "|Rated_load     | The rated max loading of bridge (in tonnes)               | continuous |\n",
    "|Scour_rating   | Only for bridges over water: the 'scour' condition        | ordinal |\n",
    "|Deck_rating    | The condition of the deck of the bridge                   | ordinal |\n",
    "|Superstr_rating| The condition of the bridge superstructure                | ordinal |\n",
    "|Substr_rating  | The condition of the bridge substructure (foundations)    | ordinal |\n",
    "\n",
    "**Note on 'scour'**: when a bridge is over (for example) a river, the flow of water in the river can undermine any bridge supports (called 'piers') in the water. This is called 'scouring' . The `Scour_rating` gives the condition with respect to possible damage from scouring. \n",
    " \n",
    "**Values of Categorical Variables** In the original data, the values of the categorical variables are represented as integers, with their meanings given in a data dictionary. In our dataset, these 'numeric codes' have been replaced with suitable names.\n",
    "\n",
    "| Variable      |      Values            |\n",
    "|:--------------|:-----------------------|\n",
    "|District       | Each district has a unique number  |\n",
    "|Toll           | Toll, Free                |\n",
    "|Maintainer     | State, County, Town or City, Agency, Private, Railroad, Toll Authority, Military, Unknown |\n",
    "|Urban          | Urban, Rural |\n",
    "|Status         | Interstate, Arterial, Minor, Local |\n",
    "|Historic       | Register, Possible, Unknown, Not historic |\n",
    "|Service_under  | Other, Highway, Railroad, Pedestrian, Interchange, Building |\n",
    "|Material       | Other, Concrete, Steel, Timber, Masonry |\n",
    "|Design         | Other, Slab, Beam, Frame, Truss, Arch, Suspension, Movable, Tunnel, Culvert, Mixed |\n",
    "|Scour_rating   | Unknown, Critical, Unstable, Stable, Protected, Dry, No waterway |\n",
    "|Deck_rating    | *Rating*: NA, Excellent, Very Good, Good, Satisfactory, Fair, Poor, Serious, Critical, Failing, Failed |\n",
    "|Superstr_rating| *Rating* |\n",
    "|Substr_rating  | *Rating* |\n",
    "    \n",
    "\n",
    "### Section 1.2 Loading the Data\n",
    "\n",
    "We can load the data from the CSV file. A 'type map' is used to set the types of each variables. Without this, Pandas guesses at the types, representing non-numeric fields as string. Instead, we represent them as Categorical Variables: using type `category` gives the default behaviour (use each unique value as a category and categories are not ordered). However, for the ordinal variables (categorical variables with an order) we must declare a suitable type explicitly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below declares a catageorical type with categories in a specified order\n",
    "# This can be used for an ordinal variable\n",
    "rating_type = pd.CategoricalDtype(\n",
    "    categories=['Failed', 'Failing', 'Critical', 'Serious', 'Poor', 'Fair', \n",
    "                'Satisfactory', 'Good', 'Very Good', 'Excellent', 'NA'], \n",
    "    ordered=True)\n",
    "\n",
    "# This one is also for an ordinal variable, but with a slightly different set of values\n",
    "scour_type = pd.CategoricalDtype(\n",
    "    categories=['Unknown', 'Critical','Unstable', 'Stable', 'Protected', 'Dry', 'No waterway'], \n",
    "    ordered=True)\n",
    "\n",
    "types_dict = { 'Structure_id': str, 'District':'category', 'Toll':'category', \n",
    "              'Maintainer':'category', 'Urban':'category', 'Status':'category', \n",
    "              'Historic':'category', 'Service_under':'category', 'Material':'category', \n",
    "              'Design':'category', \n",
    "              'Deck_rating':rating_type, 'Superstr_rating':rating_type, 'Substr_rating':rating_type, \n",
    "              'Scour_rating':scour_type}\n",
    "\n",
    "bridges = pd.read_csv('tx19_bridges_sample.csv', dtype = types_dict, index_col = 'Structure_id')\n",
    "#bridges  # uncomment to preview the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1\n",
    "Uncomment and run the following to get information about the fields (as seen by Pandas). You should notice that two variables have *null* values. You can find these using the code:\n",
    "\n",
    "    bridges.loc[(bridges.Deck_rating.isnull()) | (bridges.Superstr_rating.isnull()) ]\n",
    "\n",
    "Since there are only a small number of null, we will ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bridges.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.3: Initial Data Exploration\n",
    "This section recaps techniques from notebook 2. Do not spend too long on this at first but do look at distributions later if you need to. \n",
    "\n",
    "#### Exercise 1.2\n",
    "Answer the following questions about the distribution of the number of bridges in each **district**.\n",
    "\n",
    "1. Generate a pivot table giving the number of bridges in each district. (Hint: use `aggfunc='count'`. You need to specify a variable `values=` but any variable will do as we are only counting. See the effect of having leaving out `values=`.)\n",
    "2. Does this distribution have a max, a min, a mean and a standard deviation? Find these out.\n",
    "3. Show the distribution of the number of bridges in each district both as a bar chart and as a histogram.\n",
    "\n",
    "Note that the data is collected by the [Texas Department of Transportation](https://www.txdot.gov/content/txdot/en.html) which is organised into [districts](https://www.txdot.gov/inside-txdot/district.html). I have not been able (or very concerned) to match up the district numbers with their names. \n",
    "\n",
    "#### Exercise 1.3\n",
    "Also examine the distribution of other categorical variables, including at least one of the 'ratings'. Are some Texas bridges in a poor state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4\n",
    "Also look at the distribution of the continuous variables. Below we show a quick way to do this; the following sections discuss some issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hist method ignores categorical variables, so we can just apply to to everything\n",
    "#_ax = bridges.hist(bins=40, figsize=(14,25), layout=(6,2)) # all the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4 (Continued)\n",
    "\n",
    "1. Are any of the data variables normally distributed? Is skew present?\n",
    "2. Why are so many of the distributions shown almost all on the left side?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5 Discrete (Numeric) versus Continuous\n",
    "\n",
    "Earlier in the module, we introduced the distinction between categorical and continuous variable. This dataset has what are often called *discrete* variable. The following table summarises these distinctions.\n",
    "\n",
    "| Type of Variable | Description |\n",
    "|:-----------|:------------------------|\n",
    "| Categorical | The values are categories: they can neither be added nor ordered. Example: apple, pear, banana|\n",
    "| Ordinal     | The values are categories with an order; they cannot be added. Example: course rating: good, ok, bad |\n",
    "| Continuous  | The values are numbers from an *infinite* set of possible values. Example: length |\n",
    "| Discrete    | The values are whole numbers, from a finite (and not too large) set of possible values. Example: number of children in a family | \n",
    "\n",
    "Since discrete variables are numbers we can choose to treat them as continuous if we wish, depending on what we consider to a large set (there is reported to be a family with 21 children in the UK). Since the values can be added (as they are numbers) it would be unusual to use a categorical type for them in Pandas. \n",
    "\n",
    "It may be better to plot these variables using bar charts. Uncomment and run the code below. Then answer the questions that follow. Note that we use a log on the vertical axis. Try it without this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (a1, a2, a3) = plt.subplots(3, 1, figsize = (12, 15))\n",
    "\n",
    "#bridges.pivot_table(values='Year', index='Lanes_on', aggfunc='count').plot(\n",
    "#    ax=a1, kind='bar', logy=True, legend=False)\n",
    "#bridges.pivot_table(values='Year', index='Lanes_under', aggfunc='count').plot(\n",
    "#    ax=a2, kind='bar', logy=True, legend=False)\n",
    "#bridges.pivot_table(values='Year', index='Spans', aggfunc='count').plot(\n",
    "#    ax=a3, kind='bar', logy=True, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5 (Continued)\n",
    "\n",
    "1. It is strange that the most popular number of lanes under a bridge is zero. The are several explanations for this and the full picture is not available from the data included here. There is a variable `service_under` that shows that some bridges run over buildings - look at this. Another explanation is that the road of interest runs under the bridge so that the 'under' number refers to what is on the bridge. This needs more examination as this data has been excluded!\n",
    "2. Sometimes a number is used when the true value is unknown. Can you see a probable example of this in any of these variables. We need to ask a highways engineer from Texas (or consult a data dictionary) to be sure. \n",
    "3. Can you see any values that are hard to believe?\n",
    "\n",
    "In general, we need to check data for errors (often presenting as *outliers*). We will not do more of this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.6 \n",
    "Now that we have looked at the discrete variable separately, rerun the histogram plot without the discrete variables. Hint: use the `column` parameter to select the variables you want to include. Also try `log=True`. Interestly, this parameter is not described in Pandas, but it is the matplotlib documentation. \n",
    "\n",
    "1. Do you see some more values that could be errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Correlation of Continuous Variables\n",
    "This section focuses just on the continuous variables. The concept of *correlation* is that two variables change together: as one doe sup so does the other (positive correlation) or as one goes up the other goes down (negative). \n",
    "\n",
    "### Section 2.1: The Correlation Matrix\n",
    "The correlation coefficient between the continuous variables in the data frame can be calculated using `.corr()`. Conventionally, the categorical variables are just ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detour_Km</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lanes_on</th>\n",
       "      <th>Lanes_under</th>\n",
       "      <th>AverageDaily</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Rated_load</th>\n",
       "      <th>Trucks_percent</th>\n",
       "      <th>Future_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detour_Km</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024513</td>\n",
       "      <td>-0.111038</td>\n",
       "      <td>-0.150131</td>\n",
       "      <td>-0.136661</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>-0.129509</td>\n",
       "      <td>-0.074833</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>-0.133701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>-0.024513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064312</td>\n",
       "      <td>0.151885</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>-0.075133</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>0.092663</td>\n",
       "      <td>0.366931</td>\n",
       "      <td>-0.215144</td>\n",
       "      <td>0.068084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lanes_on</th>\n",
       "      <td>-0.111038</td>\n",
       "      <td>0.064312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>0.569665</td>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.053918</td>\n",
       "      <td>0.842755</td>\n",
       "      <td>0.196427</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>0.543820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lanes_under</th>\n",
       "      <td>-0.150131</td>\n",
       "      <td>0.151885</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366752</td>\n",
       "      <td>0.166926</td>\n",
       "      <td>0.480803</td>\n",
       "      <td>0.300220</td>\n",
       "      <td>0.203972</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>0.368653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageDaily</th>\n",
       "      <td>-0.136661</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.569665</td>\n",
       "      <td>0.366752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>0.168745</td>\n",
       "      <td>0.587129</td>\n",
       "      <td>0.194222</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>0.914798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spans</th>\n",
       "      <td>0.021051</td>\n",
       "      <td>-0.075133</td>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.166926</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609742</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.087519</td>\n",
       "      <td>0.125985</td>\n",
       "      <td>0.078115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>-0.025573</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>0.053918</td>\n",
       "      <td>0.480803</td>\n",
       "      <td>0.168745</td>\n",
       "      <td>0.609742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123974</td>\n",
       "      <td>0.149799</td>\n",
       "      <td>0.046890</td>\n",
       "      <td>0.171969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>-0.129509</td>\n",
       "      <td>0.092663</td>\n",
       "      <td>0.842755</td>\n",
       "      <td>0.300220</td>\n",
       "      <td>0.587129</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.123974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286784</td>\n",
       "      <td>0.139993</td>\n",
       "      <td>0.568987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rated_load</th>\n",
       "      <td>-0.074833</td>\n",
       "      <td>0.366931</td>\n",
       "      <td>0.196427</td>\n",
       "      <td>0.203972</td>\n",
       "      <td>0.194222</td>\n",
       "      <td>0.087519</td>\n",
       "      <td>0.149799</td>\n",
       "      <td>0.286784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179288</td>\n",
       "      <td>0.191833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trucks_percent</th>\n",
       "      <td>0.007965</td>\n",
       "      <td>-0.215144</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>0.125985</td>\n",
       "      <td>0.046890</td>\n",
       "      <td>0.139993</td>\n",
       "      <td>0.179288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future_traffic</th>\n",
       "      <td>-0.133701</td>\n",
       "      <td>0.068084</td>\n",
       "      <td>0.543820</td>\n",
       "      <td>0.368653</td>\n",
       "      <td>0.914798</td>\n",
       "      <td>0.078115</td>\n",
       "      <td>0.171969</td>\n",
       "      <td>0.568987</td>\n",
       "      <td>0.191833</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Detour_Km      Year  Lanes_on  Lanes_under  AverageDaily  \\\n",
       "Detour_Km        1.000000 -0.024513 -0.111038    -0.150131     -0.136661   \n",
       "Year            -0.024513  1.000000  0.064312     0.151885      0.057762   \n",
       "Lanes_on        -0.111038  0.064312  1.000000     0.237121      0.569665   \n",
       "Lanes_under     -0.150131  0.151885  0.237121     1.000000      0.366752   \n",
       "AverageDaily    -0.136661  0.057762  0.569665     0.366752      1.000000   \n",
       "Spans            0.021051 -0.075133  0.034389     0.166926      0.076196   \n",
       "Length          -0.025573  0.115817  0.053918     0.480803      0.168745   \n",
       "Width           -0.129509  0.092663  0.842755     0.300220      0.587129   \n",
       "Rated_load      -0.074833  0.366931  0.196427     0.203972      0.194222   \n",
       "Trucks_percent   0.007965 -0.215144 -0.009249    -0.011792      0.023467   \n",
       "Future_traffic  -0.133701  0.068084  0.543820     0.368653      0.914798   \n",
       "\n",
       "                   Spans    Length     Width  Rated_load  Trucks_percent  \\\n",
       "Detour_Km       0.021051 -0.025573 -0.129509   -0.074833        0.007965   \n",
       "Year           -0.075133  0.115817  0.092663    0.366931       -0.215144   \n",
       "Lanes_on        0.034389  0.053918  0.842755    0.196427       -0.009249   \n",
       "Lanes_under     0.166926  0.480803  0.300220    0.203972       -0.011792   \n",
       "AverageDaily    0.076196  0.168745  0.587129    0.194222        0.023467   \n",
       "Spans           1.000000  0.609742  0.080100    0.087519        0.125985   \n",
       "Length          0.609742  1.000000  0.123974    0.149799        0.046890   \n",
       "Width           0.080100  0.123974  1.000000    0.286784        0.139993   \n",
       "Rated_load      0.087519  0.149799  0.286784    1.000000        0.179288   \n",
       "Trucks_percent  0.125985  0.046890  0.139993    0.179288        1.000000   \n",
       "Future_traffic  0.078115  0.171969  0.568987    0.191833        0.023660   \n",
       "\n",
       "                Future_traffic  \n",
       "Detour_Km            -0.133701  \n",
       "Year                  0.068084  \n",
       "Lanes_on              0.543820  \n",
       "Lanes_under           0.368653  \n",
       "AverageDaily          0.914798  \n",
       "Spans                 0.078115  \n",
       "Length                0.171969  \n",
       "Width                 0.568987  \n",
       "Rated_load            0.191833  \n",
       "Trucks_percent        0.023660  \n",
       "Future_traffic        1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridges.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heat Map** The correlation is often shown as heat map. The best one (*that I have found so far*) is from the [Seaborn library](https://seaborn.pydata.org/) (`sns`). This is another library for visualisation, also built on matplotlib.\n",
    "\n",
    "Uncomment the code below to see the heat map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig,ax = plt.subplots(1,1, figsize=(15,12))\n",
    "#sns.heatmap(bridges.corr(), vmin=-1, vmax=1, cmap=sns.diverging_palette(20, 220, as_cmap=True), \n",
    "#            annot=True, ax=ax, annot_kws={\"size\": 15})\n",
    "#_y = plt.yticks(rotation=0, fontsize=15)\n",
    "#_x = plt.xticks(rotation=45, fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1\n",
    "Inspect the correlation heat map. Can the larger correlations be explained? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Scatter and other X-Y Plots\n",
    "\n",
    "This section shows how we can construct a scatter plot. \n",
    "\n",
    "The following example shows how to use the `'scatter'` plot kind. Given that we have over 30,000 bridges, what do you expect to see? Uncomment this and run it: are your fears confirmed? Do you see the problem? See also the influence that the outlier values have on the plot.\n",
    "\n",
    "Note that we have chosen two values to show on these plots: this is just for illustration.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bridges.plot(kind='scatter',  x='Year', y='AverageDaily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1: Skew and Outliers**\n",
    "\n",
    "The scatter plot is difficult to interpret because the data is very skewed and has outliers.\n",
    "1. We can show log of the value on either axis (or both). Note that this makes any relationship harder to interpret.\n",
    "2. We can filter out more extreme values. This spreads the points out as they are more evenly distributed over the range.\n",
    "\n",
    "#### Exercise 2.2 Dealing with Outliers and Skew\n",
    "The code below shows both of these techniques. Try this and try them separately as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bridges.loc[bridges.Width < 75].plot(kind='scatter',  x='Width', y='AverageDaily', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2: Very Dense Scatter Plots**\n",
    "\n",
    "We suggest three possible solutions to the problem of having so many points to show on a scatter.\n",
    "\n",
    "1. Make the dots transparent: used `alpha=0.1` where `0.1` makes the points 90% transparent allowing you to see several dots at or near the same point.\n",
    "\n",
    "2. Plot only a sample of the data points. \n",
    "\n",
    "3. Use a different kind of X-Y plot, using hexagonal binning.\n",
    "\n",
    "#### Exercise 2.3 Plotting Very Dense Scatter Plots using Transparency\n",
    "Redo the scatter using alpha of less than 1. Is this an adequate way to show this number of data points?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4 Plotting Very Dense Scatter Plots using a Sample of Data\n",
    "\n",
    "We can select a sample of the data and plot just this sample. When there is lots of data, we should still see any relationship (except for outliers). Use `bridges.sample(frac=0.01).plot(...` to select 1% of the bridge data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5 Plotting Very Dense Scatter Plots use Hex Bins\n",
    "\n",
    "The code below shows how we can plot 'hex' bins, to give a form of two dimensional density. There is no need to sample the data. However, we have limited the range - see the effect of removing this. These plots are also tuned by choosing the size of the hexagons (using the `gridsize` parameter).  \n",
    "\n",
    "You should see two dense regions (the 2-dimensional analog of bi-modal) in this plot. Can you form a hypothesis of why this might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bridges.loc[bridges.Length < 100].plot(kind='hexbin',  x='Year', y='Length',  gridsize=20, sharex=False)\n",
    "   # It is not completely clear why sharex=False is needed but without the x axis disappears. This may be a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3: The Scatter Matrix\n",
    "\n",
    "Pandas provides a function to plot 'scatter matrix', which shows a scatter plot of all the numeric variables (with distributions on the diagonal axis; kde are available as well). \n",
    "\n",
    "Uncomment the next line - wait a while - and see that 11 x 11 is not so useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_a = pd.plotting.scatter_matrix(bridges, figsize=(16,16))\n",
    "\n",
    "# The variable on the left hand side _a is useful as otherwise the return value (121 axes) is displayed. \n",
    "# We assign it to a variable to stop this happening. Starting the name with an underscore is a convention\n",
    "# for saying 'dummy variable' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.6 Categorising the Variables\n",
    "\n",
    "One way to proceed is to group the 11 variables by what they relate to. There are many ways to do this; we have chosen to have a group that are about the way the bridge is used and another about its physical structure. \n",
    "\n",
    "The code below select some variables as relating to use and then filters extreme values. Review this data frame and then plot a scatter matrix using a 25% sample and some transparency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vs = ['Detour_Km', 'AverageDaily', 'Rated_load', 'Trucks_percent', 'Future_traffic']\n",
    "use_b = bridges.loc[(bridges.Detour_Km < 200) & # (bridges.AverageDaily > 100) & \n",
    "                    (bridges.AverageDaily < 200000) & (bridges.Future_traffic < 300000), use_vs]\n",
    "#use_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.7\n",
    "Also plot the scatter matrix for the other group of variables. They are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_vs = ['Year', 'Lanes_on', 'Lanes_under', 'Spans', 'Length', 'Width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.8 (*Very Optional*)\n",
    "In some ways, it would be more useful to have scatter plots for each pair of variables, one from the list relating to use and the other from the list relating to the structure. Work out how to do this in something like a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Cross-tabulating Categorical Variables\n",
    "This section looks at the categorical variables. We first use `crosstab` to cross tabulate variables in a table (also called a contingency table). We then consider how to show conditional probability distributions using bar charts before also using a `heatmap` to display conditional probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.1 Cross Tabulation and Normalisation\n",
    "\n",
    "The following code looks at the relationship between two categorical variables, using cross tabulation which is similar to pivot. We can use the `crosstab` function in the following ways:\n",
    "\n",
    "* We can normalise over all values creates a joint probability distribution. We can add totals to this, which show the marginal probability distribution of the two variables.\n",
    "* We can normalise over the index. This makes all the rows sum to 1, giving probability of the variable on the x-axis, given the variable on the y-axis.\n",
    "* To get the other conditional probability, we swap the parameters but still normalise the index. This seems better for plotting.\n",
    "* Totals are not useful when normalising. If you include `margins=True` only the total on the unnormalised axis are given and they are not of interest.\n",
    "* It is convenient to display the table as percentages. See how this is done.\n",
    "* We do not want either totals or percentages for plotting.\n",
    "\n",
    "**Note** The variables `deck_and_mat`, `mat_and_deck`, `deck_given_mat` and `mat_given_deck` and used later, so do not overwrite them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Deck_rating</th>\n",
       "      <th>Failed</th>\n",
       "      <th>Failing</th>\n",
       "      <th>Critical</th>\n",
       "      <th>Serious</th>\n",
       "      <th>Poor</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Satisfactory</th>\n",
       "      <th>Good</th>\n",
       "      <th>Very Good</th>\n",
       "      <th>Excellent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Concrete</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.08</td>\n",
       "      <td>19.22</td>\n",
       "      <td>64.68</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masonry</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>15.38</td>\n",
       "      <td>76.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.17</td>\n",
       "      <td>22.92</td>\n",
       "      <td>35.42</td>\n",
       "      <td>33.33</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>9.11</td>\n",
       "      <td>32.78</td>\n",
       "      <td>49.23</td>\n",
       "      <td>7.71</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timber</th>\n",
       "      <td>1.08</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.51</td>\n",
       "      <td>15.70</td>\n",
       "      <td>40.22</td>\n",
       "      <td>37.63</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck_rating  Failed  Failing  Critical  Serious  Poor   Fair  Satisfactory  \\\n",
       "Material                                                                     \n",
       "Concrete       0.00     0.01      0.00     0.00  0.10   2.08         19.22   \n",
       "Masonry        0.00     0.00      0.00     0.00  0.00   0.00          7.69   \n",
       "Other          0.00     0.00      0.00     0.00  0.00   4.17         22.92   \n",
       "Steel          0.09     0.03      0.02     0.02  0.74   9.11         32.78   \n",
       "Timber         1.08     0.22      0.00     0.00  1.51  15.70         40.22   \n",
       "\n",
       "Deck_rating   Good  Very Good  Excellent  \n",
       "Material                                  \n",
       "Concrete     64.68      13.19       0.72  \n",
       "Masonry      15.38      76.92       0.00  \n",
       "Other        35.42      33.33       4.17  \n",
       "Steel        49.23       7.71       0.27  \n",
       "Timber       37.63       3.66       0.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joint probabilities - normalise all\n",
    "#  The first parameter is the index (it can be a list)\n",
    "#  The second parameter is the columns (it can be a list)\n",
    "deck_and_mat = pd.crosstab(bridges.Deck_rating, [bridges.Material], normalize='all')\n",
    "deck_and_mat_tot = pd.crosstab(bridges.Deck_rating, [bridges.Material], normalize='all', margins=True)\n",
    "mat_and_deck = pd.crosstab(bridges.Material, [bridges.Deck_rating], normalize='all')\n",
    "\n",
    "# Conditional probabilities - normalise index\n",
    "#   The first parameter is the index: since we normalise this become sthe conditioning variable\n",
    "#   The second parameter is the columns: the variable(s) whose prob dist is give for each conditioning value\n",
    "mat_given_deck = pd.crosstab(bridges.Deck_rating, [bridges.Material], normalize='index')\n",
    "deck_given_mat = pd.crosstab(bridges.Material, [bridges.Deck_rating], normalize='index')\n",
    "\n",
    "# Uncomment one of the variables (also used in next section) to see the table\n",
    "# --------------------------------------------------------------------------\n",
    "#deck_and_mat_tot.round(4) * 100\n",
    "#mat_and_deck.round(4) * 100\n",
    "#mat_given_deck.round(4) * 100\n",
    "deck_given_mat.round(4) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about Crosstab and NaN** If you have missing data represented by NaN then `pd.crosstab` just ignores it. You can replace `NaN` values using `fillna`. This is not much concern with this dataset, so we do not examine this in more detail. \n",
    "\n",
    "#### Exercise 3.1\n",
    "Look at each of the cross tabulation tables created above. Find the right table to answer the following questions.\n",
    "\n",
    "> \n",
    "> 1. What percentage of failing bridges are concrete?\n",
    "> 2. What percentage of steel bridges are in 'poor' or worse condition?\n",
    "> 3. Are there more bridges that are in good condition and made of concrete or in satisfactory condition and made of steel?\n",
    "\n",
    "#### Exercise 3.2\n",
    "\n",
    "1. Construct cross tabulations for other pairs of categorical variables. \n",
    "3. You can also use discrete variables (if there are not too many values) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3\n",
    "Try some variations of cross tabulation\n",
    "1. Above we have made the variable being conditioned on (i.e. B in p(A|B)) the index and then normalised so that the rows add to one (or 100%). Is it easier to read a conditional probability table if the columns sum to 1? Try this. For `normalize=` you can put `'all’`, `‘index’`, `‘columns’` or `False`.\n",
    "1. Try cross tabulation without normalisation: this gives counts.\n",
    "1. Try cross tabulation with 3 (or more) variables. It is easier (in your view) to have 2 variables in the index (more rows) or in the columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.2 Plotting Probability Distributions\n",
    "\n",
    "The code below shows how to plot using bar charts. By default, the x-axis shows the index variable(s). The x axis seems most appropriate for the variable being conditioned on (i.e. B in p(A|B)). The joint distribution can be shown either way around, with no obvious way to prefer one from the other. We have shown one plot as stacked, for illustration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.4 \n",
    "\n",
    "1. Uncomment and run the code below\n",
    "2. Experiment with `stacked=True` and `stacked=False`. Which do you prefer? \n",
    "1. Also plot other cross tabulations, including one with three variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate suitable axes\n",
    "#fig,(a1, a2, a3, a4) = plt.subplots(4,1,figsize=(15,20), sharey=False, sharex=False)\n",
    "#fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "# Plot one tabulation on each axis WITH CAREFUL TITLES\n",
    "#deck_and_mat.plot(kind='bar', subplots=False, ax=a1, rot=0)\n",
    "#a1.set_title('Joint Probability of Deck Rating and Main Material (plot 1)', fontsize=14)\n",
    "\n",
    "#mat_and_deck.plot(kind='bar', subplots=False, ax=a2, rot=0)\n",
    "#a2.set_title('Joint Probability of Main Material and Deck Rating (plot 2)', fontsize=14)\n",
    "\n",
    "#mat_given_deck.plot(kind='bar', subplots=False, ax=a3, rot=0, stacked=True)\n",
    "#a3.set_title('Probability of Materials, given Deck Rating', fontsize=14)\n",
    "\n",
    "#deck_given_mat.plot(kind='bar', subplots=False, ax=a4, rot=0, stacked = False)\n",
    "#a4.set_title('Probability of Deck Rating, given Material', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.5\n",
    "The code below displays a cross-tabulation using a pie chart. There is no normalisation. What is the chart actually showing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deck_and_mat = pd.crosstab(bridges.Deck_rating, [bridges.Material], normalize=False)\n",
    "#(a1,a2),(a3,a4),(a5,_) = deck_and_mat.plot(kind='pie', subplots=True, figsize=(20,20), layout=(3,2), autopct='%.1f')\n",
    "\n",
    "# remove ticks from x axis\n",
    "#_ = [a.tick_params(axis='x', which='both', bottom=False) for a in [a1,a2,a3,a4,a5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.3 Heatmap of (Conditional) Probabilities\n",
    "\n",
    "In this section we use the the heatmap to display a cross-tabulation. The heatmap of the conditional probability gives an impression of the correlation but bear in mind that p(A|B) is not equal to p(B|A), which does not match our intuition for correlation. \n",
    "\n",
    "#### Exercise 3.6\n",
    "1. Uncomment the code below and display the heatmap.\n",
    "2. Try with normalise as `columns` or `False`, changing the the title appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#super_given_deck = pd.crosstab(bridges.Deck_rating, [bridges.Superstr_rating], normalize='index')\n",
    "\n",
    "#fig,ax = plt.subplots(1,1, figsize=(12,10))\n",
    "#sns.heatmap(super_given_deck.round(4)*100, cmap=sns.light_palette('grey'), linewidths = 2,\n",
    "#            annot=True, ax=ax, annot_kws={\"size\": 13}, fmt='g')\n",
    "#ax.set_title('Superstructure Rating given Deck Rating', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Distributions of Continuous Variables, by Category\n",
    "\n",
    "We are interested to understand how the continuous variables (such as year) are *correlated* (in the general sense) with categorical variables with one (or more) of the categorical variables. This is, we can ask how the distribution of the continuous variable (or its statistics) changes given the value of the category.\n",
    "\n",
    "For example, we might be interested in the relationship between the year built and the material. We suspect that bridges are no longer built from masonry (i.e stone and brick). The problem is that the numbers in each category are different. One solution is to create separate data frames (or data frame views). However, Pandas provides two other convenient ways to do this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1 Using Box Plots to Compare the Distribution of one Variable by Another Variable\n",
    "\n",
    "Recall that a boxplot is really a visualisation of the summary statistics of a distribution. The `boxplot` can select a variable whose distribution is to be summarised (the `column=` argument) and a categorical variable (the `by=` argument) so that a separate summary is shown for each category.\n",
    "\n",
    "There are some examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (a1, a2, a3) = plt.subplots(3,1, figsize=(15,14))\n",
    "\n",
    "#bridges.boxplot(column='Year', by='Material', ax=a1)\n",
    "#bridges.boxplot(column='Year', by='Deck_rating', ax=a2)\n",
    "#bridges.boxplot(column='Year', by='Design', ax=a3)\n",
    "\n",
    "# Make the plots a bit clearer\n",
    "#fig.suptitle('')\n",
    "#[a.set_title('') for a in [a1, a2, a3]]\n",
    "#a1.set_ylabel('Year')\n",
    "#a2.set_ylabel('Year')\n",
    "#a3.set_ylabel('Length (m)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.1\n",
    "\n",
    "1. Describe the relationship between year and the construction material\n",
    "2. Draw a plot of the `AverageDaily` and the road `Status` and also of bridge `Length` and whether a `Toll` is paid. Can you explain why neither plot is very informative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very Skewed Distributions** \n",
    "\n",
    "Although a boxplot is very robust, it does not handle very skewed distributions. Most bridges are short (not very heavily used) but some are very long (or very heavily used). \n",
    "\n",
    "#### Exercise 4.2 \n",
    "The code below shows how we can create a data frame with extra columns with the logarithms of variables - such as those that have very skewed distributions. Plot these log values using a box plot. Is it easier to see if there is a relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brd_logs = bridges.assign(AverageDailyLog = np.log10(bridges.AverageDaily),\n",
    "#                         LengthLog = np.log10(bridges.Length))\n",
    "\n",
    "# Note that this code has a runtime warning: some of the values are zero, which has no logarithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.2 Using `groupby` to Partition a Data Frame\n",
    "\n",
    "The `by=` parameter of the box plot is not generally available. Instead, we use the Pandas `groupby` method. The effect of this is to partition a data frame into a set of data frame, one for each value of a categorical variable.\n",
    "\n",
    "#### Exercise 4.3 \n",
    "The following code creates a group by using the`Deck_rating` category. Uncomments and access the ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Detour_Km</th>\n",
       "      <th>Toll</th>\n",
       "      <th>Maintainer</th>\n",
       "      <th>Urban</th>\n",
       "      <th>Status</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lanes_on</th>\n",
       "      <th>Lanes_under</th>\n",
       "      <th>AverageDaily</th>\n",
       "      <th>...</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Deck_rating</th>\n",
       "      <th>Superstr_rating</th>\n",
       "      <th>Substr_rating</th>\n",
       "      <th>Rated_load</th>\n",
       "      <th>Trucks_percent</th>\n",
       "      <th>Scour_rating</th>\n",
       "      <th>Future_traffic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structure_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>010750AA0230001</th>\n",
       "      <td>District1</td>\n",
       "      <td>8</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Critical</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>010920AA0504001</th>\n",
       "      <td>District1</td>\n",
       "      <td>14</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Critical</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>052190AA0193007</th>\n",
       "      <td>District5</td>\n",
       "      <td>13</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1935</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>061950AA0184001</th>\n",
       "      <td>District6</td>\n",
       "      <td>159</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1936</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Critical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>082090AA0188001</th>\n",
       "      <td>District8</td>\n",
       "      <td>16</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>94.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Critical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>090740AA0168001</th>\n",
       "      <td>District9</td>\n",
       "      <td>5</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>090740AA0299001</th>\n",
       "      <td>District9</td>\n",
       "      <td>8</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>090740AA0301001</th>\n",
       "      <td>District9</td>\n",
       "      <td>159</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>091610AA0790001</th>\n",
       "      <td>District9</td>\n",
       "      <td>3</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Critical</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120800AA0710003</th>\n",
       "      <td>District12</td>\n",
       "      <td>159</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1996</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140110AA0194001</th>\n",
       "      <td>District14</td>\n",
       "      <td>2</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162050AA0382002</th>\n",
       "      <td>District16</td>\n",
       "      <td>3</td>\n",
       "      <td>Free</td>\n",
       "      <td>County</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Local</td>\n",
       "      <td>1950</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Failed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   District  Detour_Km  Toll Maintainer  Urban Status  Year  \\\n",
       "Structure_id                                                                  \n",
       "010750AA0230001   District1          8  Free     County  Rural  Local  1971   \n",
       "010920AA0504001   District1         14  Free     County  Rural  Local  1975   \n",
       "052190AA0193007   District5         13  Free     County  Rural  Local  1935   \n",
       "061950AA0184001   District6        159  Free     County  Rural  Local  1936   \n",
       "082090AA0188001   District8         16  Free     County  Rural  Local  1900   \n",
       "090740AA0168001   District9          5  Free     County  Rural  Local  1950   \n",
       "090740AA0299001   District9          8  Free     County  Rural  Local  1996   \n",
       "090740AA0301001   District9        159  Free     County  Rural  Local  1991   \n",
       "091610AA0790001   District9          3  Free     County  Rural  Local  1999   \n",
       "120800AA0710003  District12        159  Free     County  Rural  Local  1996   \n",
       "140110AA0194001  District14          2  Free     County  Rural  Local  1986   \n",
       "162050AA0382002  District16          3  Free     County  Rural  Local  1950   \n",
       "\n",
       "                 Lanes_on  Lanes_under  AverageDaily  ... Spans Length Width  \\\n",
       "Structure_id                                          ...                      \n",
       "010750AA0230001         1            0            10  ...     1   13.1   4.9   \n",
       "010920AA0504001         1            0            60  ...     2    7.0   3.7   \n",
       "052190AA0193007         1            0            50  ...     1   15.2   4.8   \n",
       "061950AA0184001         1            0             1  ...     3   15.9   3.7   \n",
       "082090AA0188001         1            0             1  ...     1   94.8   4.1   \n",
       "090740AA0168001         1            0            50  ...     2   13.7   4.9   \n",
       "090740AA0299001         1            0           100  ...     4   18.3   5.8   \n",
       "090740AA0301001         1            0            55  ...     3   14.9   5.6   \n",
       "091610AA0790001         2            0            70  ...     3   25.9   7.2   \n",
       "120800AA0710003         2            0            10  ...     2    9.4   6.8   \n",
       "140110AA0194001         1            0            50  ...     2   15.9   5.3   \n",
       "162050AA0382002         2            0           195  ...     3   22.9   6.0   \n",
       "\n",
       "                Deck_rating  Superstr_rating  Substr_rating  Rated_load  \\\n",
       "Structure_id                                                              \n",
       "010750AA0230001      Failed           Failed         Failed         0.0   \n",
       "010920AA0504001      Failed           Failed         Failed         0.0   \n",
       "052190AA0193007      Failed           Failed         Failed         0.0   \n",
       "061950AA0184001      Failed           Failed         Failed         0.0   \n",
       "082090AA0188001      Failed           Failed         Failed         0.0   \n",
       "090740AA0168001      Failed           Failed         Failed         0.0   \n",
       "090740AA0299001      Failed           Failed         Failed         0.0   \n",
       "090740AA0301001      Failed           Failed         Failed         0.0   \n",
       "091610AA0790001      Failed           Failed         Failed         0.0   \n",
       "120800AA0710003      Failed           Failed         Failed         0.0   \n",
       "140110AA0194001      Failed           Failed         Failed         0.0   \n",
       "162050AA0382002      Failed           Failed         Failed         0.0   \n",
       "\n",
       "                Trucks_percent Scour_rating Future_traffic  \n",
       "Structure_id                                                \n",
       "010750AA0230001            0.0     Critical             40  \n",
       "010920AA0504001            0.0     Critical            135  \n",
       "052190AA0193007            0.0       Stable             40  \n",
       "061950AA0184001            0.0     Critical              1  \n",
       "082090AA0188001            0.0     Critical              1  \n",
       "090740AA0168001            0.0       Stable             75  \n",
       "090740AA0299001            0.0       Stable             70  \n",
       "090740AA0301001            0.0       Stable             50  \n",
       "091610AA0790001            0.0     Critical            100  \n",
       "120800AA0710003            0.0       Stable             50  \n",
       "140110AA0194001            0.0       Stable            100  \n",
       "162050AA0382002            2.0       Stable            300  \n",
       "\n",
       "[12 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbyDeck = bridges.groupby(by = 'Deck_rating', dropna=False)\n",
    "\n",
    "gbyDeck.get_group('Failed')\n",
    "\n",
    "#gbyDeck.get_group('Failing')\n",
    "#gbyDeck.get_group('Good')\n",
    "#gbyDeck.get_group('Excellent')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.4\n",
    "The follow code shows a way to look at the size of groups. Run the code. Do the same for some other categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbyDeck.size().plot(kind='bar', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.5\n",
    "The following code uses `describe` on each of the groups in a `GroupBy` object (created using the `groupby` method). Run it and look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describeBy(groups, columns):\n",
    "    for (index,grp) in groups:\n",
    "        print('\\nGroup', index)\n",
    "        print('------------------')\n",
    "        print(grp.loc[:,columns].describe())\n",
    "\n",
    "# describeBy(gbyDeck, ['AverageDaily', 'Year', 'Trucks_percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.3 Reducing the Number of Categories\n",
    "\n",
    "We may need to reduce the number of categories when,as here, the sizes are very uneven. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new ordinal type for the simplified rating\n",
    "simp_rating_type = pd.CategoricalDtype(categories=['Fair_or_worse', 'Satisfactory', 'Good', \n",
    "                                                   'Very Good', 'Excellent'], ordered=True)\n",
    "# create a dictionary mapping existing to new values\n",
    "simp_d = {'Failed':'Fair_or_worse', 'Failing':'Fair_or_worse', 'Critical':'Fair_or_worse', \n",
    "          'Serious':'Fair_or_worse', 'Poor':'Fair_or_worse', 'Fair':'Fair_or_worse'}\n",
    "\n",
    "# define a function we can apply to map the values\n",
    "def simDRating(row):\n",
    "    if row.Deck_rating in simp_d:\n",
    "        return simp_d[row.Deck_rating]\n",
    "    return row.Deck_rating\n",
    "        \n",
    "\n",
    "# apply the function, creating a new column,\n",
    "nbgs = bridges.assign(SimpDeck = bridges.apply(simDRating, axis=1))\n",
    "nbgs = nbgs.astype({'SimpDeck':simp_rating_type})\n",
    "#nbgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the new column in a group by. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpDeck\n",
       "Fair_or_worse     1347\n",
       "Satisfactory      7588\n",
       "Good             21006\n",
       "Very Good         4132\n",
       "Excellent          215\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbySDeck = nbgs.groupby(by = 'SimpDeck')\n",
    "gbySDeck.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.4 Comparing Groups using Histograms and Kernel Density\n",
    "\n",
    "Once we have created groups, these can be displayed using either histograms or kernel density estimators.\n",
    "\n",
    "#### Exercise 4.6 Histogram of Groups\n",
    "The histogram method can be applied directly to the 'group by' object. The default behaviour is to show a separate histogram for each group. \n",
    "\n",
    "1. Uncomment and run the code below. Note that the x-axes are different for each group (but using `sharex=True` does not work as we might hope).\n",
    "2. Create histograms for other continuous variables or grouped by other categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axs = gbySDeck.hist(column=['Year', 'Rated_load'], alpha=0.3, bins=15, density=True, figsize=(14,4), legend=True)\n",
    "      # The parameter log=True can be useful\n",
    "\n",
    "# This sets the titles\n",
    "#names = ['Fair_or_worse', 'Satisfactory', 'Good', 'Very Good', 'Excellent']\n",
    "#_t = [axs[name][0][col].set_title('Deck rating is ' + name) for name in names for col in [0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can create the axes first and then have the histograms for different group share the same axis. The disadvantage here is that the *excellent* group has a very skewed distribution. The only way (I know of) to remove this is to filter it out of the data frame before creating the groups.  \n",
    "\n",
    "#### Exercise 4.7 \n",
    "\n",
    "1. Uncomment and run the code below. Do you see why the group for bridges with an 'excellent' deck condition makes it harder to see the distributions? Outliers are also a problem.\n",
    "2. Create histograms for other continuous variables or grouped by other categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "#fig, axs = plt.subplots(2, 1, figsize=(14,10))\n",
    "\n",
    "# plot the histogram using these axes\n",
    "#_x = gbySDeck.hist(column=['Year', 'Rated_load'], ax = axs, alpha=0.3, bins=15, density=True) #, log=True)\n",
    "\n",
    "# Set a legend, using the group names \n",
    "#name = ['Fair_or_worse', 'Satisfactory', 'Good', 'Very Good', 'Excellent']\n",
    "#axs[0].legend(names)\n",
    "#axs[1].legend(names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting Kernel Density Estimation** A KDE can also be used to show the distribution. Although the Pandas library has a KDE plot type, the version from the Seaborn library is better. The code is slightly longer as we have to add each group separately. However, this has the advantage of flexibility. For example, we can omit the 'excellent' group. \n",
    "\n",
    "#### Exercise 4.8\n",
    "\n",
    "1. Uncomment and run the code below.\n",
    "2. To what extent and how do the ages of bridges with the different deck conditions differ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fair = gbySDeck.get_group('Fair_or_worse')\n",
    "d_sat = gbySDeck.get_group('Satisfactory')\n",
    "d_gd = gbySDeck.get_group('Good')\n",
    "d_vg = gbySDeck.get_group('Very Good')\n",
    "d_ex = gbySDeck.get_group('Excellent')\n",
    "\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(14,5))\n",
    "var = 'Year'\n",
    "\n",
    "#sns.kdeplot(data=d_fair[var], label='Fair', ax=ax1, alpha=0.3, shade=True)\n",
    "#sns.kdeplot(data=d_sat[var], label='Satisfactory', ax=ax1, alpha=0.3, shade=True)\n",
    "#sns.kdeplot(data=d_gd[var], label='Good', ax=ax1, alpha=0.3, shade=True)\n",
    "#sns.kdeplot(data=d_vg[var], label='Very Good', ax=ax1, alpha=0.3, shade=True)\n",
    "# omit this one #sns.kdeplot(data=d_ex['Year'], label='Excellent', ax=ax1, alpha=0.3, shade=True)\n",
    "\n",
    "#ax1.set_xlabel(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
