{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab session 3: Data exploration and data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "The purpose of this lab session is to provide you with an opportunity to gain experience in **data exploration** and **data visualisation** using typical Python libraries.\n",
    "\n",
    "- This lab is the second part of a **two-week assignment** that covers weeks 3 and 4, which is due on **Friday 29th October 10am**.\n",
    "- The assignment will account for 10% of your overall grade. Questions in this lab sheet will contribute to 5% of your overall grade; questions in the lab sheet for week 3 will cover for another 5% of your overall grade.\n",
    "- <font color = 'maroon'>The last section of this notebook includes the questions that are assessed towards your final grade.</font> \n",
    "\n",
    "This session starts with a tutorial that uses examples to introduce you to the practical knowledge that you will need for the corresponding assignment. We highly recommend that you read the following tutorials if you need a gentler introduction to the libraries that we use:\n",
    "- [Numpy quickstart tutorial](https://numpy.org/devdocs/user/quickstart.html)\n",
    "- [Numpy: basic broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "- [Matplotlib](https://matplotlib.org/tutorials/introductory/pyplot.html)\n",
    "- [Seaborn](https://seaborn.pydata.org/tutorial/relational.html)\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important notes about the assignment: \n",
    "\n",
    "- **PLAGIARISM** <ins>is an irreversible non-negotiable failure in the course</ins> (if in doubt of what constitutes plagiarism, ask!). \n",
    "- The total assessed coursework is worth 40% of your final grade.\n",
    "- There will be 9 lab sessions and 4 assignments.\n",
    "- One assignment will cover 2 consecutive lab sessions and will be worth 10 marks (percentages of your final grade).\n",
    "- The submission cut-off date will be 7 days after the deadline and penalties will be applied for late submissions in accordance with the School policy on late submissions.\n",
    "- You are asked to submit a **report** that should answer the questions specified in the last section of this notebook. The report should be in a **single PDF document** (so **NOT** *doc, docx, notebook* etc). This single PDF document will include your answers to both the week 3 and week 4 labs.\n",
    "- No other means of submission other than submitting your assignment through the appropriate QM+ link are acceptable at any time. Submissions sent via email will **not** be considered.\n",
    "- Please name your report as follows: Assignment1-StudentName-StudentNumber.pdf\n",
    "- Cases of **Extenuating Circumstances (ECs)** have to go through the proper procedure of the School in due time. Only cases approved by the School in due time can be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Exploring and visualising the graduation rate dataset\n",
    "\n",
    "\n",
    "In order to present typical Python functionalities for data exploration and data visualisation, we will use the graduation rate dataset (http://roycekimmons.com/tools/generated_data) as part of a working example.\n",
    "\n",
    "Note that this is a **synthetic** dataset that presents a familiar setting for the sake of simplicity. Therefore, this dataset should not be used to draw conclusions about students in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the graduation rate dataset\n",
    "\n",
    "The graduation rate dataset is stored in a file called ``graduation_rate.csv``, which can be found together with this notebook. You can inspect this file using any text editor. The file contains 1001 lines. The first line contains the name of the features, separated by commas. The remaining lines contain one observation per line. The values for the features of each observation are also separated by lines.\n",
    "\n",
    "The library ``pandas`` has a convenient function called ``read_csv``, which expects a file that follows the convention described above. This function returns a ``DataFrame``, which represents the data set.\n",
    "\n",
    "The function ``display`` used within a notebook is similar to the Python function ``print``, but presents a ``DataFrame`` in a much more convenient format. By default, only the first five rows and the last five rows of a large ``DataFrame`` are shown.\n",
    "\n",
    "This initial inspection reveals that most features are numerical, except for the feature ``parental level of education``, which has multiple text values. In order to display the valid values for this feature, we select the corresponding column from the ``DataFrame``, and use the method ``Series.unique``. This method returns the unique values across a ``Series``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset (http://roycekimmons.com/tools/generated_data)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('graduation_rate.csv')\n",
    "\n",
    "print('Dataset (head and tail):')\n",
    "display(df)\n",
    "\n",
    "print('\\nParental levels of education:')\n",
    "print(df['parental level of education'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing features\n",
    "\n",
    "In order to establish a natural ordering over ``parental level of education``, the corresponding column of the ``DataFrame`` is substituted by a column of ordinal features created using the function ``pd.Categorical``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_order = ['some high school', 'high school', 'some college', \"associate's degree\", \"bachelor's degree\", \"master's degree\"]\n",
    "\n",
    "df['parental level of education'] = pd.Categorical(df['parental level of education'],\n",
    "                                                   ordered=True,\n",
    "                                                   categories=education_order)\n",
    "\n",
    "display(df['parental level of education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data summarisation\n",
    "\n",
    "The method ``DataFrame.describe`` can be used to compute most of the univariate summaries that we have covered during the lectures. For each feature, this method computes the mean, standard deviation, minimum, maximum, median, lower quartile, and upper quartile. \n",
    "\n",
    "Note that ``DataFrame.describe`` detects and omits the categorical feature ``parental level of education``, since those summaries would not be useful. Instead, it is possible to use the method ``Series.value_counts`` to derive the frequency of each value of this feature.\n",
    "\n",
    "The method ``DataFrame.corr`` can be used to compute the correlation matrix for the (numerical) features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Univariate summaries:')\n",
    "display(df.describe())\n",
    "print(\"Frequency of parental levels of education:\")\n",
    "\n",
    "# relative frequency by dividing with len(df)\n",
    "freq_education = df['parental level of education'].value_counts()/len(df)\n",
    "display(freq_education)\n",
    "\n",
    "print(\"\\nCorrelation coefficients:\")\n",
    "display(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Table visualisation\n",
    "\n",
    "The method ``DataFrame.sort_values`` can be used to sort the rows of a ``DataFrame`` by the value of a specific feature, in ascending or descending order. For instance, we can use this method to sort students by ``college gpa``.\n",
    "\n",
    "We can also use **slicing** to select a range of observations from a ``DataFrame``. For example, we may sort the students by increasing ``parental income`` and then select the first ten students (with the lowest ``parental income``).\n",
    "\n",
    "When a ``DataFrame`` is indexed by a list of boolean values that has as many elements as the ``DataFrame`` has rows, only the rows that correspond to ``True`` values are returned. This also works when the list used for indexing is represented by a ``Series``. This functionality can be used to select rows that pass a test based on their features. For example, we may use it to select the students whose parents are educated beyond high school. \n",
    "\n",
    "The method ``DataFrame.groupby`` provides a simple way to partition observations into groups based on the value of chosen categorical features (for example, ``parental level of education``) and operating independently on each group (for example, computing the mean of the numerical features independently for each group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.to_latex()) # Print a table for use with LaTeX\n",
    "print('Sorting by college gpa:')\n",
    "display(df.sort_values(by='college gpa', ascending=False))\n",
    "\n",
    "print('Selecting the ten students with lowest parental income :')\n",
    "display(df.sort_values(by='parental income', ascending=True)[0:10])\n",
    "\n",
    "print('Sorting by high school gpa the students whose parents are educated beyond high school')\n",
    "# Note that a boolean sequence can be used to index a DataFrame\n",
    "display(df[df['parental level of education'] > 'high school'].sort_values(by='high school gpa', ascending=False))\n",
    "\n",
    "print('Grouping by parental level of education and computing the mean for other features:')\n",
    "display(df.groupby('parental level of education').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Histograms\n",
    "\n",
    "The library ``seaborn`` provides a high-level interface for drawing appealing graphics using ``matplotlib``.\n",
    "\n",
    "The following snippet is used to configure the appearance of ``seaborn`` graphics in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = set(['retina'])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``distplot`` can be used to create a histogram with a specified number of bins for a given column of a ``DataFrame`` (or any list of numbers). For example, it may be used to create a histogram of ``high school gpa`` and ``college gpa``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['high school gpa'], bins=None, kde=False)\n",
    "plt.title('Histogram: high school gpa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['college gpa'], bins=None, kde=False)\n",
    "plt.title('Histogram: college gpa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Pie charts\n",
    "\n",
    "The library ``seaborn`` currently has no function to create pie charts (likely due to the fact that this type of visualisation is often discouraged). The ``matplotlib`` function ``pie`` (``matplotlib.pyplot.pie``) can be used to depict an array of frequencies by a pie chart. For example, we may display the frequencies of ``parental level of education`` computed in the data summarization section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(freq_education, labels=freq_education.index)\n",
    "plt.title('Pie chart: parental level of education')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Box Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``boxplot`` can be used to create a box plot for a specific feature. For example, it can be used to create a box plot for ``parental income``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['parental income'], orient='v')\n",
    "plt.title('Boxplot: parental income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``boxplot`` is also capable of grouping observations by a categorical feature and creating one box plot for each resulting group. For example, we may create one box plot of ``parental income`` for each ``parental level of education``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='parental level of education', y='parental income', data=df)\n",
    "plt.title('Boxplot: parental income, grouped by parental level of education')\n",
    "\n",
    "# Wrap xticks \n",
    "import textwrap\n",
    "ax.set_xticklabels([textwrap.fill(t.get_text(), 10)  for t in ax.get_xticklabels()])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Scatter plots\n",
    "\n",
    "The function ``scatterplot`` can be used to create a scatter plot for any given pair of features, while the function ``pairplot`` can be used to create a scatter plot matrix. \n",
    "\n",
    "The resulting points can be coloured according to a categorical feature given by the parameter ``hue``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='ACT composite score', y='SAT total score', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(df, hue='parental level of education', diag_kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Distance matrices\n",
    "\n",
    "In order to visualise a distance matrix, it is often important to group the observations in a dataset by a given categorical feature.\n",
    "\n",
    "For example, we may sort the observations by increasing ``parental level of education``. Because the feature ``parental level of education`` is ordinal but not numerical, we may also decide to remove it from consideration when computing distances between observations.\n",
    "\n",
    "Furthermore, it is always important to scale different features so that their magnitudes are comparable when computing distances. For example, we may use the ``sklearn`` class ``StandardScaler`` to standardize each feature individually. The method ``StandardScaler.fit_transform`` expects a numpy matrix containing observations across rows and returns a corresponding matrix with standardized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_sorted = df.sort_values(by='parental level of education', ascending=True)\n",
    "parental_education_sorted = df_sorted['parental level of education']\n",
    "\n",
    "X = df_sorted.drop(columns='parental level of education').to_numpy()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``scipy`` function ``pdist`` (``scipy.spatial.distance.pdist``) can be used to compute pairwise Euclidean distances between observations in a matrix, while the function ``squareform`` (``scipy.spatial.distance.squareform``) can be used to convert the return of ``pdist`` into the representation that we expect (``pdist`` returns a condensed representation of a symmetric matrix).\n",
    "\n",
    "Finally, the ``seaborn`` function ``heatmap`` can be used to create a heat map for the corresponding distance matrix (for a chosen colormap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "dist = distance.squareform(distance.pdist(X))\n",
    "sns.heatmap(dist, square=True, xticklabels=False, yticklabels=False,\n",
    "                cmap='Blues')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class ``MDS`` from the library ``sklearn`` implements dimensionality reduction through multidimensional scaling. A standardized matrix of observations as the one used to compute the distance matrix in the example above is an appropriate input to the method ``MDS.fit_transform``, which outputs a matrix that contains a two-dimensional point for each observation in the input matrix. A scatter plot can be used to depict this output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "    \n",
    "embedding = MDS(n_components=2)\n",
    "    \n",
    "Xp = embedding.fit_transform(X)\n",
    "df_projection = pd.DataFrame({'x': Xp[:, 0], 'y': Xp[:, 1],\n",
    "                              'parental level of education': parental_education_sorted})\n",
    "\n",
    "sns.scatterplot(x='x', y='y', hue='parental level of education', data=df_projection)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class ``TSNE`` from the library ``sklearn`` implements dimensionality reduction through t-distributed stochastic neighbour embedding (t-SNE). Its interface is analogous to the one provided by the class ``MDS``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embedding = TSNE(n_components=2, perplexity=100)\n",
    "\n",
    "Xp = embedding.fit_transform(X)\n",
    "df_projection = pd.DataFrame({'x': Xp[:, 0], 'y': Xp[:, 1],\n",
    "                              'parental level of education': parental_education_sorted})\n",
    "sns.scatterplot(x='x', y='y', hue='parental level of education', data=df_projection)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, each point obtained by t-SNE is coloured according to whether the parents of the corresponding student have a higher education degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projection['parents have degree'] = (df['parental level of education'] > 'some college')\n",
    "sns.scatterplot(x='x', y='y', hue='parents have degree', data=df_projection)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Visualising an analytic function\n",
    "\n",
    "In order to present Python functionalities related to visualising scalar fields and vector fields, we will use the analytic function $f: \\mathbb{R}^2 \\to \\mathbb{R}$ given by $f(x,y) = z = x^2 + y^2$ as a working example.\n",
    "\n",
    "The ``numpy`` function ``linspace`` can be used to create a list of evenly spaced numbers in a specified interval, while the function ``meshgrid`` can be used to create all possible combinations of numbers from two given lists of numbers. \n",
    "\n",
    "In our example, the function ``meshgrid`` returns two matrices. The first matrix replicates the numbers of the first list across rows. In our example, this matrix represents positions along the x-axis. The second matrix replicates the numbers of the second list across columns. In our example, this matrix represents positions along the y-axis.\n",
    "\n",
    "By applying elementwise operations that ultimately combine the two matrices, it is possible to evaluate a function of two variables on every element of a grid defined by the two lists of numbers generated by ``linspace``. The resulting dataset can also be represented by a ``DataFrame``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_range = np.linspace(-1, 1, 10)\n",
    "y_range = np.linspace(-1, 1, 10)\n",
    "\n",
    "# meshgrid: X[i, j] == x_range[j] and Y[i, j] == y_range[i]\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "# Z[i, j] == f(x_range[j], y_range[i])\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "# Dataset representation\n",
    "df = pd.DataFrame({'x': X.reshape(-1), 'y': Y.reshape(-1), 'z = f(x,y)': Z.reshape(-1)})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Heat maps\n",
    "\n",
    "The ``matplotlib`` function ``imshow`` can be used to create a heatmap through nearest neighbour interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation: point (x, y) is colored according to the value z of the nearest point in the dataset\n",
    "plt.imshow(Z, cmap='Blues', aspect='equal', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "# xticks and yticks would show Z matrix indices\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``matplotlib`` function ``imshow`` can also be used to create a heatmap through bilinear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation: point (x, y) is colored according to the (weighted average) value z of the four nearest points\n",
    "plt.imshow(Z, cmap='Blues', aspect='equal', interpolation='bilinear')\n",
    "plt.colorbar()\n",
    "\n",
    "# xticks and yticks would show Z matrix indices\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Contour plots\n",
    "\n",
    "The ``matplotlib`` function ``contour`` can be used to create a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = plt.contour(X, Y, Z, levels=10, cmap='Blues')\n",
    "plt.clabel(CS, inline=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Surface plots\n",
    "\n",
    "The library ``matplotlib`` is also capable of creating (interactive) three-dimensional plots. Surface plots can be created using the function ``plot_surface``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='Blues', linewidth=0, antialiased=True)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Quiver plots\n",
    "\n",
    "The ``matplotlib`` function ``quiver`` can be used to create quiver plots. For example, we may use the ``numpy`` function ``gradient`` to approximate the gradient function $\\nabla f$ of the scalar field $f$ by the finite differences method, which can then be represented by a quiver plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DY, DX = np.gradient(Z)\n",
    "plt.quiver(X, Y, DX, DY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 [part 2 of 2]\n",
    "\n",
    "For your answers to the assignment, please include include your workings (e.g. equations, code) when this is relevant to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In Section 1, what kind of relationship can be inferred from summary statistics regarding ``ACT composite score`` and ``SAT total score``? Which visualisations make this relationship apparent? [0.5 marks out of 5]\n",
    "\n",
    "2. Based on the box plots presented in Section 1, what is the relationship between ``parental level of education`` and ``parental income``? Using table visualisation, find and show the entire rows that correspond to the outliers regarding ``parental income`` whose parents have a master's degree. [0.5 marks out of 5]\n",
    "\n",
    "3. Using an example, explain the importance of scaling features so that their magnitudes are comparable when computing distances. [0.5 marks out of 5]\n",
    "\n",
    "4. In Section 1, the distance matrix visualisation is not very informative. However, it is still possible to infer that the average distance between students whose parents only have some high school education and students whose parents have a master's degree is larger than the average distance between students whose parents only have some high school education. Explain how this inference is possible from the visualisation. [0.5 marks out of 5]\n",
    "\n",
    "5. In Section 2, increase the number of evenly spaced numbers from 10 to 100 for both axes and observe the corresponding heat map created through nearest neighbour interpolation. Read about this interpolation method and explain what you observed. [0.5 marks out of 5]\n",
    "\n",
    "6. The function ``load_wine`` from ``sklearn.datasets`` can be used to load the *wine dataset* into a ``DataFrame`` by using the commands ``data = load_wine()``, ``df = pd.DataFrame(data.data, columns=data.feature_names)``, and ``df['target'] = pd.Series(data.target)``. \n",
    "\n",
    "    6.1. Load the wine dataset. Compute the frequency of each value of the 'target' feature.  [0.5 marks out of 5]\n",
    "    \n",
    "    6.2. Compute univariate and multivariate summaries for all numerical features (except from the target feature). Group observations by the target feature and compute the corresponding **median** for each numerical feature. [0.5 marks out of 5]\n",
    "    \n",
    "    6.3. Group observations by the target feature and create one box plot of ``alcohol`` for each group. [0.5 marks out of 5]\n",
    "    \n",
    "    6.4. Create a scatter plot for the pair of **distinct** numerical features with the highest correlation.  [0.5 marks out of 5]\n",
    "    \n",
    "    6.5. Exclude the target feature, standardize the remaining numerical features, and display a projection obtained by multidimensional scaling. Color the points by the target feature. [0.5 marks out of 5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
