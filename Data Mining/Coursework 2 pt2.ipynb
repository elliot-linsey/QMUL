{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88624fb7",
   "metadata": {},
   "source": [
    "## Q.1\n",
    "The formula for Euclidean distance is $d(p,q) = \\sqrt{\\,\\sum_{i=1}^n (q_i - p_i)^2}$\n",
    "\n",
    "With these x values below we find the distances between x1 and x2 to x3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "554bd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = (1,-1)\n",
    "x2 = (-1,1)\n",
    "x3 = (-2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42fe2cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance 1 = 5.0\n",
      "distance 2 = 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "dist1 = ((-2-1)**2 + (3--1)**2)**0.5\n",
    "print(\"distance 1 = \" + str(dist1))\n",
    "\n",
    "dist2 = ((-2--1)**2 + (3-1)**2)**0.5\n",
    "print(\"distance 2 = \" + str(dist2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13b3ef",
   "metadata": {},
   "source": [
    "It would classify x3 as class y2 as the euclidean distance is closest to point x2 at 2.24 compared to x1 at 5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767214df",
   "metadata": {},
   "source": [
    "## Q.2\n",
    "When K is odd in a KNN algorithm we do not need a tie-breaking policy because one class will always have a greater number of points closer to the new point than the other class. For example if K=5, the closest you can get to a tie will be 3 points of class y1 and 2 points of class y2 being the nearest neighbours, in this situation and with all odd K numbers the point will always be designated as the class with the highest number of neighbours, therefore it would be classed as label y1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c16c5",
   "metadata": {},
   "source": [
    "## Q.3\n",
    "A classifier that has an accuracy of 99.9% can be terrible for some datasets if 0.1% of the data is another class. This algorithm will label every data point as the same class and therefore miss the 0.1% that is different. While this appears to give a very high accuracy, it is actually not truly classifying anything rather than just assigning the same class to all data points. This can be extremely bad if misidentifying that 0.1% of data results in a far greater cost than identifying 99.9% of the other data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cd4ea",
   "metadata": {},
   "source": [
    "## Q.4\n",
    "A precision of 1.0 and low recall of 0.1 means that out of the data you predicted positive, all were correctly identified as true positive. However, the low recall means that you actually missed a lot of the true positives and mislabelled them as false negatives. Therefore, when it detects a positive it can be trusted but it is far less trustworthy when detecting negatives as there is a high chance they could be positive. In terms of this classifier, it should not be trusted if it detects that point to not belong to class y and it should be trusted if it detects it to belong to class y. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974fe85",
   "metadata": {},
   "source": [
    "## Q.5\n",
    "The K=1 classifier struggled the most with classes 4 and 9, correctly identifying 40 4s but misidentifying 4 of them (10%) as 9s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d2036",
   "metadata": {},
   "source": [
    "## Q.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29f2b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Selecting the training data from the original dataset\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "X, y = pickle.load(f, encoding='latin1')[0]\n",
    "f.close()\n",
    "\n",
    "# Subsampling\n",
    "sample_size = 2000\n",
    "X, y = X[:sample_size], y[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f60c3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58cd72f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy: 0.9275\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "print('Test dataset accuracy: ' + str(clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c7bb0",
   "metadata": {},
   "source": [
    "## Q.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fb18926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter settings: {'max_features': 0.1, 'n_estimators': 200}.\n",
      "Average accuracy across folds of best hyperparameter setting: 0.9106250000000001.\n",
      "Test dataset accuracy of best hyperparameter setting: 0.9075.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators': [50,100,200], 'max_features': [0.1,0.25]}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_cv = GridSearchCV(rfc, parameters, cv=5)\n",
    "rfc_cv.fit(X_train, y_train)\n",
    "print('Best hyperparameter settings: {0}.'.format(rfc_cv.best_params_))\n",
    "print('Average accuracy across folds of best hyperparameter setting: {0}.'.format(rfc_cv.best_score_))\n",
    "print('Test dataset accuracy of best hyperparameter setting: {0}.'.format(rfc_cv.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
